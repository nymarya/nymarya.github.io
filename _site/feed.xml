<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2021-07-01T14:31:20-03:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Mayra Azevedo</title><subtitle>Web development | Data science | Machine Learning | Computer science</subtitle><entry><title type="html">Predizendo notas do ENEM</title><link href="http://localhost:4000/predizendo-notas-do-enem/" rel="alternate" type="text/html" title="Predizendo notas do ENEM" /><published>2020-08-26T00:00:00-03:00</published><updated>2020-08-26T00:00:00-03:00</updated><id>http://localhost:4000/predizendo-notas-do-enem</id><content type="html" xml:base="http://localhost:4000/predizendo-notas-do-enem/">&lt;p&gt;Para entrar na aceleração de Data Science do &lt;a href=&quot;https://www.codenation.dev&quot;&gt;Codenation&lt;/a&gt;, os alunos tinham que predizer as notas de matemática do enem 2016. A “nota de corte” era 90% de acerto das notas e minha primeira submissão deve ter sido uns 91%. Na oitava semana veio o penúltimo desafio, que era o mesmo da inscrição. Então nada melhor do que aproveitar a oportunidade para refazer a solução e usar os novos conhecimentos para tentar melhorar a pontuação. O código está disponível &lt;a href=&quot;https://github.com/nymarya/aceleradev/blob/master/enem-2&quot;&gt;aqui&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;o-feijão-com-arroz&quot;&gt;O feijão com arroz&lt;/h3&gt;

&lt;p&gt;Para os 90%, fui no básico: um modelo simples, um pré-processamento mais cuidadoso.&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;https://media.giphy.com/media/xT1XH14zaGcdC4j2bC/giphy.gif&quot; /&gt;
&lt;/div&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;O modelo escolhido foi o LinearRegression, com os parâmetros já pré-estabelecidos.&lt;/p&gt;

&lt;p&gt;No tratamento, primeiro utilizei &lt;a href=&quot;https://github.com/pandas-profiling/pandas-profiling&quot;&gt;pandas-profiling&lt;/a&gt; para ter uma visão geral do banco de treinamento. A ferramenta dá todas as estatísticas e já indica quais colunas tem correlação entre si. Retirei essas. Retirei também as que tinham 50% ou mais de valores nulos ou as colunas que tinham valor constante. Feita a separação entre features numericas e categoricas. As numéricas imputei os valores nulos com -1 e padronizei com &lt;a href=&quot;https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html&quot;&gt;StandardScaler&lt;/a&gt;. As categóricas imputei com a string “N/A” e usei o &lt;a href=&quot;https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html&quot;&gt;OneHotEncoder&lt;/a&gt;. Isso aumenta significativamente o numero de colunas, então tive que usar o TruncatedSVD para reduzir a dimensionalidade, que sem tratamento são meras 61462 features.&lt;/p&gt;

&lt;h3 id=&quot;digievoluindo-a-solução&quot;&gt;Digievoluindo a solução&lt;/h3&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;https://media.giphy.com/media/nDb2WPoK832fK/giphy.gif&quot; /&gt;
&lt;/div&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Feito o básico, resta fazer um trabalho mais rebuscado de engenharias de dados. A começar por mais uma etapa de limpeza de dados, dessa vez utilizando da &lt;a href=&quot;https://github.com/nymarya/aceleradev/blob/master/enem-2/src/features/build_features.py#L110&quot;&gt;correlação&lt;/a&gt; para retirar algumas colunas. Para evitar redundância de dados, são retiradas as colunas numéricas que tem correlação maior que 0.5 ou menor que -0.2 com a coluna alvo &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NU_NOTA_MT&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Algumas coisas simples a serem testadas seria trocar o StandardScaler por outro normalizador como MinMaxScaler, RobustScaler, ou Normalizer. Essa mudança pode ser muito importante pelo fato de que o StandardScaler assume que seus dados seguem uma distribuição normal. De fato, no &lt;a href=&quot;https://github.com/nymarya/aceleradev/blob/master/enem-4/&quot;&gt;desafio&lt;/a&gt; da semana seguinte, a mudança de StandardScaler para RobustScaler representou uma diferença de uns 5% no desempenho, um salto de 93% para 98%, mas neste caso o resultado não foi tão impactante.&lt;/p&gt;

&lt;p&gt;Outra opção seria trocar o encoder por outro como CatBoost ou &lt;a href=&quot;https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html&quot;&gt;OrdinalEncoder&lt;/a&gt;, que, ao invés de cirar uma coluna para cada categoria como o OneHotEncoder, apenas tranforma as categorias na forma númerica. O primeiro não consegui inserir no código, mas o segundo foi testado e os resultados estão na tabela no  começo da próxima seção.&lt;/p&gt;

&lt;p&gt;Também foram feitos experimentos com a redução de dimensionalidade testando &lt;a href=&quot;https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html&quot;&gt;RFE&lt;/a&gt;,  &lt;a href=&quot;https://scikit-learn.org/stable/auto_examples/neighbors/plot_nca_dim_reduction.html&quot;&gt;LDA, NCA&lt;/a&gt; ou &lt;a href=&quot;https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html&quot;&gt;SelectKBest&lt;/a&gt;. O segundo e o terceiro não deram certo por não funcionarem com matriz esparsa (que é no que os dados se transformam após os passos anteriores). O primeiro, por ser recursivo, acaba sendo incompatível com o OneHotEncoder pela gigantesca quantidade de colunas geradas. O SelectKBest também apresentava um problema semelhante. Testei aplicando TruncatedSVD e depois outros para reduzir, mas não deu bom: muita demora, pouca mudança. As outras funções de redução mais lentas funcionaram com OrdinalEncoder por não aumentar a cardinalidade das colunas.&lt;/p&gt;

&lt;p&gt;Por fim, em relação aos modelos de regressão, foram testados LinearRegression, &lt;a href=&quot;https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.TheilSenRegressor.html&quot;&gt;TheisenRegressor&lt;/a&gt; e &lt;a href=&quot;https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html&quot;&gt;RandomForestRegressor&lt;/a&gt; e &lt;a href=&quot;https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html&quot;&gt;DecisionTreeRegressor&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;avaliando-as-avaliações&quot;&gt;Avaliando as avaliações&lt;/h3&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Correlação&lt;/th&gt;
      &lt;th&gt;Scaler/Normalizer&lt;/th&gt;
      &lt;th&gt;Encoder&lt;/th&gt;
      &lt;th&gt;Reduce_dim&lt;/th&gt;
      &lt;th&gt;Model&lt;/th&gt;
      &lt;th&gt;Score&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Sim&lt;/td&gt;
      &lt;td&gt;Normalizer&lt;/td&gt;
      &lt;td&gt;OneHotEncoder&lt;/td&gt;
      &lt;td&gt;SelectKBest(30)&lt;/td&gt;
      &lt;td&gt;LR&lt;/td&gt;
      &lt;td&gt;91.72&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Sim&lt;/td&gt;
      &lt;td&gt;RobustScaler&lt;/td&gt;
      &lt;td&gt;OrdinalEncoder&lt;/td&gt;
      &lt;td&gt;SelectKBest(30)&lt;/td&gt;
      &lt;td&gt;LR&lt;/td&gt;
      &lt;td&gt;93.28&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Sim&lt;/td&gt;
      &lt;td&gt;RobustScaler&lt;/td&gt;
      &lt;td&gt;OneHotEncoder&lt;/td&gt;
      &lt;td&gt;SelectKBest(10)&lt;/td&gt;
      &lt;td&gt;LR&lt;/td&gt;
      &lt;td&gt;93.25&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Sim&lt;/td&gt;
      &lt;td&gt;RobustScaler&lt;/td&gt;
      &lt;td&gt;OneHotEncoder&lt;/td&gt;
      &lt;td&gt;SelectKBest(50)&lt;/td&gt;
      &lt;td&gt;TheisenRegressor&lt;/td&gt;
      &lt;td&gt;92.52&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Sim&lt;/td&gt;
      &lt;td&gt;QuantileTransformer&lt;/td&gt;
      &lt;td&gt;OneHotEncoder&lt;/td&gt;
      &lt;td&gt;SelectKBest(50)&lt;/td&gt;
      &lt;td&gt;TheisenRegressor&lt;/td&gt;
      &lt;td&gt;93.07&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Não&lt;/td&gt;
      &lt;td&gt;QuantileTransformer&lt;/td&gt;
      &lt;td&gt;OneHotEncoder&lt;/td&gt;
      &lt;td&gt;SelectKBest(50)&lt;/td&gt;
      &lt;td&gt;TheisenRegressor&lt;/td&gt;
      &lt;td&gt;93.36&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Não&lt;/td&gt;
      &lt;td&gt;RobustScaler&lt;/td&gt;
      &lt;td&gt;OneHotEncoder&lt;/td&gt;
      &lt;td&gt;SelectKBest(50)&lt;/td&gt;
      &lt;td&gt;LR&lt;/td&gt;
      &lt;td&gt;93.37&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Não&lt;/td&gt;
      &lt;td&gt;RobustScaler&lt;/td&gt;
      &lt;td&gt;OneHotEncoder&lt;/td&gt;
      &lt;td&gt;RFE(50, LR)&lt;/td&gt;
      &lt;td&gt;LR&lt;/td&gt;
      &lt;td&gt;93.31&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Não&lt;/td&gt;
      &lt;td&gt;RobustScaler&lt;/td&gt;
      &lt;td&gt;OneHotEncoder&lt;/td&gt;
      &lt;td&gt;RFE(30, LR)&lt;/td&gt;
      &lt;td&gt;LR&lt;/td&gt;
      &lt;td&gt;93.36&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Não&lt;/td&gt;
      &lt;td&gt;RobustScaler&lt;/td&gt;
      &lt;td&gt;OneHotEncoder&lt;/td&gt;
      &lt;td&gt;RFE(30, SVR)&lt;/td&gt;
      &lt;td&gt;LR&lt;/td&gt;
      &lt;td&gt;93.37&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Não&lt;/td&gt;
      &lt;td&gt;RobustScaler&lt;/td&gt;
      &lt;td&gt;OneHotEncoder&lt;/td&gt;
      &lt;td&gt;SelectKBest(50)&lt;/td&gt;
      &lt;td&gt;RandomForest&lt;/td&gt;
      &lt;td&gt;93.5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Não&lt;/td&gt;
      &lt;td&gt;RobustScaler&lt;/td&gt;
      &lt;td&gt;OneHotEncoder&lt;/td&gt;
      &lt;td&gt;SelectKBest(50)&lt;/td&gt;
      &lt;td&gt;RandomForest(n_estimator=50)&lt;/td&gt;
      &lt;td&gt;93.56&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Não&lt;/td&gt;
      &lt;td&gt;RobustScaler&lt;/td&gt;
      &lt;td&gt;OneHotEncoder&lt;/td&gt;
      &lt;td&gt;SelectKBest(50)&lt;/td&gt;
      &lt;td&gt;RandomForest( n_estimators=50, max_depth=4, min_samples_split=4,                                   max_features=0.5)&lt;/td&gt;
      &lt;td&gt;93.64&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Não&lt;/td&gt;
      &lt;td&gt;RobustScaler&lt;/td&gt;
      &lt;td&gt;OneHotEncoder&lt;/td&gt;
      &lt;td&gt;SelectKBest(50)&lt;/td&gt;
      &lt;td&gt;DecisionTreeRegressor&lt;/td&gt;
      &lt;td&gt;91&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Tirando o primeiro, todos os algoritmos tem algum fator aleatório, o que quer dizer que para ter uma noção boa do resultado, tem que ser feitas várias execuções para analisar estatisticamente os resultados. Por exemplo, o melhor resultado encontrado foi com RandomForestRegressor, mas ao rodar várias vezes o índice não foi observado novamente muito menos melhorou. De forma geral, os métodos mais rebuscados não tiveram uma diferença tão grande em relação à boa e velha regressão linear.&lt;/p&gt;

&lt;p&gt;Concluindo, numa situação de vida real certamente o mais vantajoso, dentre os cenários vistos, seria não sair do feijão com arroz (regressão linear), apenas adicionar umas hortaliças para incrementar o PF (investir no tratamento dos dados).&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Disclaimer: os pontos mais importantes do curso, pessoalmente falando, foram as aulas sobre metodologia científica e estatística, coisas que não foram abordadas nesse post.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Enfim, é isto. Até mais!&lt;/p&gt;

&lt;h2 id=&quot;links-úteis&quot;&gt;Links úteis&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://benalexkeen.com/feature-scaling-with-scikit-learn/&quot;&gt;Feature Scaling with scikit-learn&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/nymarya/aceleradev/tree/master/enem-2&quot;&gt;Repositório&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><category term="python" /><category term="predição" /><category term="pandas" /><category term="enem" /><summary type="html">Para entrar na aceleração de Data Science do Codenation, os alunos tinham que predizer as notas de matemática do enem 2016. A “nota de corte” era 90% de acerto das notas e minha primeira submissão deve ter sido uns 91%. Na oitava semana veio o penúltimo desafio, que era o mesmo da inscrição. Então nada melhor do que aproveitar a oportunidade para refazer a solução e usar os novos conhecimentos para tentar melhorar a pontuação. O código está disponível aqui.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://www.provafacilnaweb.com.br/wp-content/uploads/2018/10/corrigir-prova-f%C3%A1cil.jpg" /></entry><entry><title type="html">Portfólio automatizado no README</title><link href="http://localhost:4000/portfolio-automatizado-no-readme/" rel="alternate" type="text/html" title="Portfólio automatizado no README" /><published>2020-07-15T00:00:00-03:00</published><updated>2020-07-15T00:00:00-03:00</updated><id>http://localhost:4000/portfolio-automatizado-no-readme</id><content type="html" xml:base="http://localhost:4000/portfolio-automatizado-no-readme/">&lt;p&gt;No dia 10 de julho de 2020, estava eu calmamente navegando pela minha timeline do Twiter, quando me aparece o tweet abaixo:&lt;/p&gt;

&lt;div&gt;
&lt;blockquote class=&quot;twitter-tweet&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Made myself a self-updating GitHub personal README! It uses a GitHub Action to update itself with my latest GitHub releases, blog entries and TILs &lt;a href=&quot;https://t.co/Eve7FOrwYK&quot;&gt;https://t.co/Eve7FOrwYK&lt;/a&gt; &lt;a href=&quot;https://t.co/oJPXLtFdgM&quot;&gt;pic.twitter.com/oJPXLtFdgM&lt;/a&gt;&lt;/p&gt;&amp;mdash; Simon Willison (@simonw) &lt;a href=&quot;https://twitter.com/simonw/status/1281435464474324993?ref_src=twsrc%5Etfw&quot;&gt;July 10, 2020&lt;/a&gt;&lt;/blockquote&gt; &lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;/div&gt;

&lt;p&gt;Para um desenvolvedor sua existência já está resumida na própria bio do GitHub, na página &lt;a href=&quot;https://nymarya.github.io&quot;&gt;about&lt;/a&gt; do site pessoal, na descrição do LinkedIn, às vezes até na descrição do Twitter, e com a possibilidade de automatizar. Depois da invenção do Simon, a feature nova pareceu mais interessante, podendo dar um diferencial em relação às outras de poder trazer informações sintetizadas que não precisam ser ajustadas manualmente (e consequentemente esquecidas de serem atualizadas).&lt;/p&gt;

&lt;h3 id=&quot;começando-a-automatização-readme&quot;&gt;Começando a automatização README&lt;/h3&gt;

&lt;p&gt;O primeiro passo é escolher quais informações devem aparecer. No meu caso, queria mostrar os posts e um resumo do que tem no meu GitHub, as linguagens que estão presentes nele.&lt;/p&gt;

&lt;p&gt;O próprio resumo escolhi escrever manualmente por motivos de: queria usar emoticons; queria escrever em inglês e português; algumas informações são pessoais, como os hobbies, e não encontraria lugares de onde tirar a informação; e até poderia criar um script que simplemente acrescenta o texto que eu escolhi, mas não acho que ficaria um código bonito e organizado.&lt;/p&gt;

&lt;p&gt;Pensado isso, é hora de colocar a mão no código.&lt;/p&gt;

&lt;h3 id=&quot;inserindo-posts-com-beautifulsoup&quot;&gt;Inserindo posts com BeautifulSoup&lt;/h3&gt;

&lt;p&gt;Simon em seu &lt;a href=&quot;https://simonwillison.net/2020/Jul/10/self-updating-profile-readme/&quot;&gt;post&lt;/a&gt; usa uma forma mais robusta e organizada para recuperar os posts, mas infelizmente meu blog no Github Pages não me dá as mesmas ferramentas. Porém, como a estrutura do HTML é bem organizada, não foi difícil recuperar o que eu queria.&lt;/p&gt;

&lt;p&gt;A biblioteca &lt;a href=&quot;https://pypi.org/project/beautifulsoup4/&quot;&gt;BeautifulSoup&lt;/a&gt; é ótima para minerar informações de sites. Para pegar os posts separados por cada língua, recuperei o HTML da &lt;a href=&quot;https://nymarya.github.io/categories&quot;&gt;página&lt;/a&gt; onde os posts já estão divididos, identifiquei onde fica cada categoria, e simplemente salvei o endereço, título e data do número de links que eu queria. O código todo, que tem aproximadamente 30 linhas) está &lt;a href=&quot;https://github.com/nymarya/nymarya/blob/master/posts.py&quot;&gt;aqui&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;inserindo-resumo-das-linguagens&quot;&gt;Inserindo resumo das linguagens&lt;/h3&gt;

&lt;p&gt;Mais uma vez, Simon utilizou uma forma um pouco mais elegante. Dessa vez, foi usando a API em GraphQl para recuperar informações do GitHub.&lt;/p&gt;

&lt;p&gt;Resolvi usar a API REST pela praticidade. Usei ela duas vezes: uma para recuperar os nomes dos repositórios (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;https://api.github.com/users/&amp;lt;usuario&amp;gt;/repos&lt;/code&gt;) e outra para recuperar as linguagens em cada repositório (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;https://api.github.com/repos/&amp;lt;usuario&amp;gt;/&amp;lt;repo&amp;gt;/languages'&lt;/code&gt;). A versão sem autenticação da API, além de acessar só os repositórios públicos, tem um limite de 60 requisições por hora, então para quem possui 60 repositórios públicos ou mais o recomendado é usar autenticação. Todas elas são consultadas utilizando a biblioteca requests.&lt;/p&gt;

&lt;p&gt;A resposta da segunda API consiste em um dicionário com cada linguagem e sua contagem de bytes. Assim, para saber a proporção basta ir unindo essas informações e no final calcular as porcentagens. Para a exibição, é usada uma tabela onde na primeira linha ficam as logos das ferramentas (boa parte das logos vem desse &lt;a href=&quot;https://github.com/abranhe/programming-languages-logos&quot;&gt;repositório&lt;/a&gt; e na segunda os nome e as porcentagem de código em que são usadas. O código com todas essas funções está &lt;a href=&quot;https://github.com/nymarya/nymarya/blob/master/repositories.py&quot;&gt;aqui&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;agora-sim-a-automatização&quot;&gt;Agora sim a automatização&lt;/h3&gt;

&lt;p&gt;Todo o processo de escrita no arquivo é feita no arquivo &lt;a href=&quot;https://github.com/nymarya/nymarya/blob/master/build_readme.py&quot;&gt;build_readme.py&lt;/a&gt;. Mas para fazer o preenchimento do arquivo primeiro precisamos indicar no README.md aonde os textos vão ser colocados. Isso é feito com comentários no markdown, que marcam as seções:&lt;/p&gt;

&lt;div class=&quot;language-markdown highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;&amp;lt;!-- &amp;lt;nome da seção&amp;gt;&lt;/span&gt; starts --&amp;gt;
&lt;span class=&quot;c&quot;&gt;&amp;lt;!-- &amp;lt;nome da seção&amp;gt;&lt;/span&gt; ends --&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Daí, usando a biblioteca &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;re&lt;/code&gt; podemos usar expressões regulares para identificar esses blocos. A expressão usada é &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&quot;&amp;lt;!-- &amp;lt;nome da seção&amp;gt; starts --&amp;gt;.*&amp;lt;!-- &amp;lt;nome da seção&amp;gt; ends --&amp;gt;&quot;&lt;/code&gt;. Na hora de inserir o texto, os comentários se mantém, para na próxima atualização a seção poder ser encontrada novamente, e os caracteres &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.*&lt;/code&gt; são substituídos pelo conteúdo de fato, consequentemente também reescrevendo o texto anterior.&lt;/p&gt;

&lt;p&gt;O passo final é configurar o workflow no Github Actions. Isso é feito indo para a aba específica, escolhendo “set up a workflow yourself” e então adicionando os comandos para configurar o Python e o pip, instalar dependências que estão no requeirements.txt, atualizar o README.md e finalmente dar commit no resultado, além de ajustar o cron para que a tarefa rode a cada 1 hora, entre 1:00 e 23:00. Ao salvar o &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;main.yml&lt;/code&gt; que contém as configurações na pasta &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.github/workflows&lt;/code&gt;, o GitHub Actions vai identificar o arquivo. O workflow é basicamente o mesmo do Simon, a diferença é que o dele ainda inclui um comando para pegar variáveis de ambiente.&lt;/p&gt;

&lt;h3 id=&quot;para-quem-tiver-mais-tempo-e-disposição&quot;&gt;Para quem tiver mais tempo e disposição&lt;/h3&gt;

&lt;p&gt;Existe uma série de coisas que poderiam ser automatizadas. Os releases mais recentes (como Simon fez), contagem de commits, interações no StackOverflow (não olhei se eles tem API, se não tiverem certamente o BeautifulSoup resolve), trabalho atual e formação do LinkedIn (se tiverem API deve ser paga, então novamente poderia usar BeautifulSoup), publicações no LinkedIn, posts do Medium, vídeos ou episódios de podcasts mais recentes para quem é desse mundo, e por aí vai.&lt;/p&gt;

&lt;p&gt;Ansiosa para ver quais ideias vão surgir. Até mais!&lt;/p&gt;

&lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://simonwillison.net/2020/Jul/10/self-updating-profile-readme/&quot;&gt;Post do Simon onde ele explica o que ele fez&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://simonwillison.net/2020/Apr/20/self-rewriting-readme/&quot;&gt;Outro post do Simon sobre automatização do README&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><category term="python" /><category term="github actions" /><category term="readme" /><summary type="html">No dia 10 de julho de 2020, estava eu calmamente navegando pela minha timeline do Twiter, quando me aparece o tweet abaixo:</summary></entry><entry><title type="html">Self-updating portfolio on README</title><link href="http://localhost:4000/self-updating-portfolio-on-readme/" rel="alternate" type="text/html" title="Self-updating portfolio on README" /><published>2020-07-15T00:00:00-03:00</published><updated>2020-07-15T00:00:00-03:00</updated><id>http://localhost:4000/self-updating-portfolio-on-readme</id><content type="html" xml:base="http://localhost:4000/self-updating-portfolio-on-readme/">&lt;p&gt;At July 10h, 2020, I was happily navigating through my Twitter timeline when this tweet popped to my eyes:&lt;/p&gt;

&lt;div&gt;
&lt;blockquote class=&quot;twitter-tweet&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Made myself a self-updating GitHub personal README! It uses a GitHub Action to update itself with my latest GitHub releases, blog entries and TILs &lt;a href=&quot;https://t.co/Eve7FOrwYK&quot;&gt;https://t.co/Eve7FOrwYK&lt;/a&gt; &lt;a href=&quot;https://t.co/oJPXLtFdgM&quot;&gt;pic.twitter.com/oJPXLtFdgM&lt;/a&gt;&lt;/p&gt;— Simon Willison (@simonw) &lt;a href=&quot;https://twitter.com/simonw/status/1281435464474324993?ref_src=twsrc%5Etfw&quot;&gt;July 10, 2020&lt;/a&gt;&lt;/blockquote&gt; &lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;/div&gt;

&lt;p&gt;A developer’s existence is already described in a GitHub profile, the &lt;a href=&quot;https://nymarya.github.io&quot;&gt;about&lt;/a&gt; page of a personal website, the LinkedIn description, sometimes even a Twitter bio, and the automated approach was the thing that made me want to build a README on GitHub. After seeing Simon’s idea, the new feature looked more interesting, offering an opportunity to show synthesized information that doesn’t require manual updating (and therefore decreases the risk of not being updated at all), a quality that the other options don’t present.&lt;/p&gt;

&lt;h3 id=&quot;starting-an-automated-readme&quot;&gt;Starting an automated README&lt;/h3&gt;

&lt;p&gt;The first step is to choose which informations should appear. In my case, I wanted to show my posts and an overview of the tools used in my Github repositories.&lt;/p&gt;

&lt;p&gt;The auto-description itself I choose to write manually because: I wanted to use emojis; to write posts both in English and Portuguese; some personal information, such as hobbies, I couldn’t retrieve from anywhere; and, yes, I could create a script to simply append the text that I would manually choose, but I don’t think it would look pretty and tidy.&lt;/p&gt;

&lt;p&gt;With that in mind, it’s time to start.&lt;/p&gt;

&lt;h3 id=&quot;adding-posts-with-beautifulsoup&quot;&gt;Adding posts with BeautifulSoup&lt;/h3&gt;

&lt;p&gt;In his &lt;a href=&quot;https://simonwillison.net/2020/Jul/10/self-updating-profile-readme/&quot;&gt;post&lt;/a&gt;, Simon retrieves his posts in more elegantly, but my Github Pages blog doesn’t offer me the same tools. However, it has an HTML structured that is very well-formed, so it was easy to get what I wanted from it.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&quot;https://pypi.org/project/beautifulsoup4/&quot;&gt;BeautifulSoup&lt;/a&gt; library is great for mining information from websites. To get the posts divided by each language, I got the HTML of the &lt;a href=&quot;https://nymarya.github.io/categories&quot;&gt;page&lt;/a&gt; where the posts are categorized, identified where (meaning: which tag) was located each category, and simply recovered the address, title, and date of a number (previously chosen) of posts. The full code is available &lt;a href=&quot;https://github.com/nymarya/nymarya/blob/master/posts.py&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;adding-profile-overview&quot;&gt;Adding profile overview&lt;/h3&gt;

&lt;p&gt;Once again, Simon’s solution is somewhat more sophisticated. This time, he used the Github’s GraphQL API to retrieve data from GitHub in a way that calls way fewer HTTP requests.&lt;/p&gt;

&lt;p&gt;I decided to use the REST API for practical reasons. I used it twice: once to get the names of the repositories (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;https://api.github.com/users/&amp;lt;usuario&amp;gt;/repo&lt;/code&gt;) and once to get the languages used in each repository (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;https://api.github.com/repos/&amp;lt;usuario&amp;gt;/&amp;lt;repo&amp;gt;/languages'&lt;/code&gt;). The unanthenticated version of the Github API, besides providing access only for public repositories, has a limit of 60 requests per hour, so if you have 60 repositories or more, you should use at least the authenticated version. All requests are made with the self-named library, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;requests&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The response for the second API consists of a dictionary containing each language and its byte count. Then, to get the proportion is only needed to append all information and finally calculate the percentages. To show this information, I used a table that contains the logos in the first line (a great number of those come from this &lt;a href=&quot;https://github.com/abranhe/programming-languages-logos&quot;&gt;repository&lt;/a&gt;) and the second line shows the name and percentage of code in which each language is used. The code is available &lt;a href=&quot;https://github.com/nymarya/nymarya/blob/master/repositories.py&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;finally-the-self-updating-part&quot;&gt;Finally, the self-updating part&lt;/h3&gt;

&lt;p&gt;All writing process is defined in the &lt;a href=&quot;https://github.com/nymarya/nymarya/blob/master/build_readme.py&quot;&gt;build_readme.py&lt;/a&gt; file. But to insert text in the file, first, it is necessary to indicate in the README.md where the information will be placed. This is done by making comments in the markdown that will mark the sections:&lt;/p&gt;

&lt;div class=&quot;language-markdown highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;&amp;lt;!-- &amp;lt;section name&amp;gt;&lt;/span&gt; starts --&amp;gt;
&lt;span class=&quot;c&quot;&gt;&amp;lt;!-- &amp;lt;section name&amp;gt;&lt;/span&gt; ends --&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Then, using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;re&lt;/code&gt; library we can use regular expressions to identify these blocks. The expression used &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&quot;&amp;lt;!-- &amp;lt;section name&amp;gt; starts --&amp;gt;.*&amp;lt;!-- &amp;lt;section name&amp;gt; ends --&amp;gt;&quot;&lt;/code&gt;. The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.*&lt;/code&gt; characters is used to capture all text inside the section, so in the next update, all previous content will be replaced with the new one. When inserting the text per se, the comments must remain around the new content, because that way the block can be found when the script runs again.&lt;/p&gt;

&lt;p&gt;The final step is to set up the workflow with Github Actions. This is done by going to the tab, choosing “set up a workflow yourself” and then adding the commands to set up python, configure pip, install dependencies from requeirements.txt, update README.md and finally committing the result, besides setting the cron so the task will run every hour. When you save the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;main.yml&lt;/code&gt; containing the configurations in the directory &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.github/workflows&lt;/code&gt;, o GitHub Actions will identify the file right away. The workflow is almost the same as Simon’s, the only difference is that his setup has one more command to get environmental variables.&lt;/p&gt;

&lt;h3 id=&quot;for-those-who-have-time-and-energy&quot;&gt;For those who have time and energy&lt;/h3&gt;

&lt;p&gt;There is still a bunch of stuff that can be automated. The most recent releases (as Simon did), counting the commits, questions and answers from StackOverflow (I don’t know if they have an API, if don’t certainly BeautifulSoup is there for you), current job and education info on LinkedIn (again API or BeautifulSoup must do the job), publications on LinkedIn, posts on Medium, most recent videos or podcasts, and so on. Creativity is welcome.&lt;/p&gt;

&lt;p&gt;I’m anxious to see the next ideas. See ya!&lt;/p&gt;

&lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://simonwillison.net/2020/Jul/10/self-updating-profile-readme/&quot;&gt;Simon’s post where he explains it all&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://simonwillison.net/2020/Apr/20/self-rewriting-readme/&quot;&gt;Yet another Simon’s post on README automation&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><category term="python" /><category term="github actions" /><category term="readme" /><summary type="html">At July 10h, 2020, I was happily navigating through my Twitter timeline when this tweet popped to my eyes:</summary></entry><entry><title type="html">CNNS: A convolução</title><link href="http://localhost:4000/cnns-a-convolucao/" rel="alternate" type="text/html" title="CNNS: A convolução" /><published>2019-11-17T00:00:00-03:00</published><updated>2019-11-17T00:00:00-03:00</updated><id>http://localhost:4000/cnns-a-convolucao</id><content type="html" xml:base="http://localhost:4000/cnns-a-convolucao/">&lt;p&gt;Este é o primeiro post de uma série sobre deep learning, especialmente Redes Neurais Convolucionais (em inglês: Convolutional Neural Networks, ou CNNs) que consiste de dois post teóricos e um mais prático, discorrendo sobre um modelo específico. Vamos começar com o C da sigla em inglês, CNN.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Convolução&lt;/strong&gt; é um termo usado na área da matemática para descrever a operação sobre duas funções que produzem uma terceira função expressando como a primeira é modificada pela outra. Eu sempre me recordo de uma aula na qual o professor explicou esse conceito de uma maneira bem simples. Imagine que você está entre dois palcos durante um festival de música: se você se mover em direção a um ou outro, ouvirá melhor alguma das músicas. Se ficar no meio, os sinais ficam muito misturados. Esta confusão de ruídos é a convolução em ação.&lt;/p&gt;

&lt;h2 id=&quot;sobre-imagens&quot;&gt;Sobre imagens&lt;/h2&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;https://media.giphy.com/media/8b5gDEqjO5BKM/giphy.gif&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;Primeiro, o básico de imagens. Para o computador, uma imagem não passa de de uma matrix de inteiros. Quando a imagem é em tons de cinza, cada número entre 0 e 255 representa a luminosidade de um pixel. Existem duas maneiras de representar figuras RGB. A primeira é como um grupo de 3 inteiros que compoem um pixel, com cada elemento do trio representando o valor de vermelho, verde e azul, respectivamente. Na outra forma, a imagem possui dimensões mxnx3, tendo uma camada para cada cor.&lt;/p&gt;

&lt;p&gt;Em relação a processamento de imagens, convolucionar significa executar várias multiplicações de matrizes entre a matrix que representa a imagem e a  [máscara](https://en.wikipedia.org/wiki/Kernel_(image_processing). Deste modo, nós podemos aplicar filtros, seja para detecção de bordas, efeitos de blurring ou de sharpening.&lt;/p&gt;

&lt;h2 id=&quot;tipos-de-convolução-de-imagem&quot;&gt;Tipos de convolução de imagem&lt;/h2&gt;

&lt;p&gt;Embora uma multiplicação de matrizes convencional requeira que o número de colunas da primeira matrix seja igual ao número de linhas da segunda matriz, o processo de convolução não possui este tipo de condição. As dimensões do kernel não precisam bater com as da imagem, visto que a convolução não equivale a um produto convecional. Ao invés disso, a operação é realizada sucessivamente sobre a figura, como se fosse uma janela deslizante movendo sobre a imagem.&lt;/p&gt;

&lt;p&gt;Considerando que os formatos não estão adequados, existem tipos de convolução cujos resultos tem dimensões diferentes. O método &lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.convolve2d.html&quot;&gt;convolve&lt;/a&gt; do módulo scipy possui três modos: &lt;em&gt;full&lt;/em&gt;, no qual os sinais não se sobrepõe completamente nas bordas da operação e podem acontecer efeitos nas bordas; &lt;em&gt;same&lt;/em&gt;, no qual o resultado tem o mesmo tamanho da imagem; e &lt;em&gt;valid&lt;/em&gt;, onde o product consiste apenas dos elementos que não dependem de zero-padding.&lt;/p&gt;

&lt;h2 id=&quot;sobre-matemática&quot;&gt;Sobre matemática&lt;/h2&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;https://media.giphy.com/media/26xBI73gWquCBBCDe/giphy.gif&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;A operação, como dito anteriormente, é muito similiar à multiplicação de matrizes comum. As diferenças começãm com o tamanho da matriz final. No modo &lt;em&gt;full&lt;/em&gt;, a matriz resultante C tem tamanho &lt;em&gt;m&lt;/em&gt; que combina o tamanho da matriz kernel K e a imagem B, conforma a equação abaixo:&lt;/p&gt;

\[m = |K| + |B| - 1\]

&lt;p&gt;Os valores de \(C\) são obtidos ao multiplicar K e B.&lt;/p&gt;

\[C(i, j) = \sum_{p=0}^{i+1} \sum_{q=0}^{j+1} K(p,q) B(i - p + 1, j - q + 1)\]

&lt;p&gt;onde \(i\) e \(j\) são posições em \(C\), e a notação \(M(a, b)\) denota a elemento na a-ésima linha e b-ésima coluna.&lt;/p&gt;

&lt;h2 id=&quot;convolucionar-para-aprender&quot;&gt;Convolucionar para aprender&lt;/h2&gt;

&lt;p&gt;A inspiração de usar a ideia de convolução para construir um algoritmo de aprendizado de máquina vem de um mecanismo biológico encontrado no cérebro de mamíferos. O córtex visual contem grupos de neurônios que são modulados por &lt;strong&gt;campos receptivos&lt;/strong&gt;, que “&lt;a href=&quot;https://en.wikipedia.org/wiki/Receptive_field&quot;&gt;podem provocar reações neurais quando estimuladas&lt;/a&gt;”. Campos receptivos podem se sobrepor e repetir entre células visiznhas, de forma que atuam como filtros locais sobre o que recebem.&lt;/p&gt;

&lt;p&gt;O &lt;a href=&quot;https://doi.org/10.1113%2Fjphysiol.1968.sp008455&quot;&gt;estudo&lt;/a&gt;, que traz informações sobre a região, divide as células em dois tipos: &lt;em&gt;simples&lt;/em&gt;, que reagem a padrões específicos de seu campo receptivo; e &lt;em&gt;complexas&lt;/em&gt;, que tem campos receptivos maiores e não são sensíveis à exata posição de um padrão na área.&lt;/p&gt;

&lt;h2 id=&quot;discussão&quot;&gt;Discussão&lt;/h2&gt;

&lt;p&gt;É importante (além de interessante! ) aprender sobre todos os passos no processo do aprendizado computacional, e é especialmente poderoso enteder a razão pela qual o modelo foi criado de certa maneira. Nos próximos posts, vamos continuar a ver teoria e depois investigar e treinar um modelo de deep learning.
Até mais!&lt;/p&gt;

&lt;h2 id=&quot;para-saber-mais--referências&quot;&gt;Para saber mais &amp;amp; referências&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://docs.opencv.org/master/d2/d96/tutorial_py_table_of_contents_imgproc.html&quot;&gt;Processamento de imagens com OpenCV&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://cs231n.github.io/convolutional-networks/&quot;&gt;CS123N&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.nature.com/articles/s42003-018-0110-y&quot;&gt;Activations of DCNNs are aligned with gamma band activty of human visual cortex&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://books.google.com/books?id=8YrxWojxUA4C&amp;amp;pg=PA106&quot;&gt;Brain and the visual perception&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1363130&quot;&gt;Receptive fields of single neurones in the cat’s striate cortex&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><category term="deep learning" /><category term="CNN" /><summary type="html">Este é o primeiro post de uma série sobre deep learning, especialmente Redes Neurais Convolucionais (em inglês: Convolutional Neural Networks, ou CNNs) que consiste de dois post teóricos e um mais prático, discorrendo sobre um modelo específico. Vamos começar com o C da sigla em inglês, CNN.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://i.stack.imgur.com/VC1TX.png" /></entry><entry><title type="html">CNNS: The convolution</title><link href="http://localhost:4000/cnns-the-convolution/" rel="alternate" type="text/html" title="CNNS: The convolution" /><published>2019-11-17T00:00:00-03:00</published><updated>2019-11-17T00:00:00-03:00</updated><id>http://localhost:4000/cnns-the-convolution</id><content type="html" xml:base="http://localhost:4000/cnns-the-convolution/">&lt;p&gt;This post is the first of a series on deep learning, specifically Convolutional Neural Networks (CNNs), that consists of two theorical posts and one more practical, discussing a particular model. Let’s start with the C of the initials CNN.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Convolution&lt;/strong&gt; is a term used in mathematics to describing the operation on two functions that produces a third function expressing how the shape of one is modified by the other. I always remember a class in which the teacher explained this idea using a very simplistic example. Imagine that you are standing between two stages during a music festival: if you move closer to one or another, you will listen better to one song. If you stay in the middle, the signals are too mixed. This confusion is the convolution in action.&lt;/p&gt;

&lt;h2 id=&quot;talking-images&quot;&gt;Talking images&lt;/h2&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;https://media.giphy.com/media/8b5gDEqjO5BKM/giphy.gif&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;First, the basics of images. To the computer, an image is nothing but a matrix of integers. When the picture is b&amp;amp;w, each integer between 0 and 255 represents the luminosity of the pixel. There are two ways of representing RGB figures. The first is a group of 3 integers that compose a pixel, with each of them representing red, blue, or green value. On another approach, the image with dimensions mxnx3 has one layer for each color.&lt;/p&gt;

&lt;p&gt;In terms of image processing, convolute means executing multiple matrix multiplications between the matrix representing the image and the [mask](https://en.wikipedia.org/wiki/Kernel_(image_processing). Hence, we can apply several transformation filters, such as edge detection, blurring and sharpening effects.&lt;/p&gt;

&lt;h2 id=&quot;types-of-image-convolution&quot;&gt;Types of image convolution&lt;/h2&gt;

&lt;p&gt;Although a conventional matrix multiplication requires that the number of columns of the 1st matrix must equal the number of rows of the 2nd matrix, the convolution process has no such condition. The kernel’s dimensions don’t need to match the image, as the convolution is not the same as a traditional product. Instead, the operation is repeated successively across the picture, as such as a sliding window moving over the image.&lt;/p&gt;

&lt;p&gt;Considering that the shapes do not match, there are several types of convolution that result in distinct dimensions. The &lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.convolve2d.html&quot;&gt;convolve&lt;/a&gt; method in the scipy module presents three modes: &lt;em&gt;full&lt;/em&gt;, in which the signals do not overlap completely at the end-points of the operation and boundary effects may occur; &lt;em&gt;same&lt;/em&gt;, in which the outcome is the same size as the image; and &lt;em&gt;valid&lt;/em&gt;, where the product consists only of those elements that do not rely on zero-padding.&lt;/p&gt;

&lt;h2 id=&quot;talking-math&quot;&gt;Talking math&lt;/h2&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;https://media.giphy.com/media/26xBI73gWquCBBCDe/giphy.gif&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;The operation, as said before, is very similar to standard matrix multiplication. The differences begin with the size of the final matrix. When in the mode &lt;em&gt;full&lt;/em&gt;, the resulting matrix C has the size &lt;em&gt;m&lt;/em&gt; that combines the size of the kernel matrix K and the image B, as the equation below shows:&lt;/p&gt;

\[m = |K| + |B| - 1\]

&lt;p&gt;The values of \(C\) are obtained by multiplying K and B.&lt;/p&gt;

\[C(i, j) = \sum_{p=0}^{i+1} \sum_{q=0}^{j+1} K(p,q) B(i - p + 1, j - q + 1)\]

&lt;p&gt;where \(i\) and \(j\) are some positions in \(C\), and the notation \(M(a, b)\) denotes the element on the a-th row and b-th column.&lt;/p&gt;

&lt;h2 id=&quot;convolute-and-learn&quot;&gt;Convolute and learn&lt;/h2&gt;

&lt;p&gt;The inspiration for using the idea of convolution to build a machine learning technique comes from a biological mechanism present in the brain of mammals. The visual cortex contains groups of neurons that are modulated by &lt;strong&gt;receptive fields&lt;/strong&gt;, that “&lt;a href=&quot;https://en.wikipedia.org/wiki/Receptive_field&quot;&gt;can elicit neuronal responses when stimulated&lt;/a&gt;”. Receptive fields overlap and repeat between neighboring cells, so they act as local filters over what they receive.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&quot;https://doi.org/10.1113%2Fjphysiol.1968.sp008455&quot;&gt;study&lt;/a&gt;, that brings information about that region, divides the cells into two types: &lt;em&gt;simple&lt;/em&gt;, that respond to specific patterns from within its receptive field; and &lt;em&gt;complex&lt;/em&gt;, that have larger receptive fields and are insensitive to the exact position of the pattern in the area.&lt;/p&gt;

&lt;h2 id=&quot;final-thoughts&quot;&gt;Final thoughts&lt;/h2&gt;

&lt;p&gt;It is important (and also interesting!) to learn about all the steps in the computational learning process, and it is especially powerful to understand the reason why the model was built in a particular way. In the next posts, we will continue to see some theory and then dissect and train a &lt;del&gt;really&lt;/del&gt; deep learning model.&lt;/p&gt;

&lt;p&gt;Stay tuned!&lt;/p&gt;

&lt;h2 id=&quot;further-reading--references&quot;&gt;Further reading &amp;amp; references&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://docs.opencv.org/master/d2/d96/tutorial_py_table_of_contents_imgproc.html&quot;&gt;Image processing with OpenCV&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://cs231n.github.io/convolutional-networks/&quot;&gt;CS123N&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.nature.com/articles/s42003-018-0110-y&quot;&gt;Activations of DCNNs are aligned with gamma band activty of human visual cortex&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://books.google.com/books?id=8YrxWojxUA4C&amp;amp;pg=PA106&quot;&gt;Brain and the visual perception&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1363130&quot;&gt;Receptive fields of single neurones in the cat’s striate cortex&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><category term="deep learning" /><category term="CNN" /><summary type="html">This post is the first of a series on deep learning, specifically Convolutional Neural Networks (CNNs), that consists of two theorical posts and one more practical, discussing a particular model. Let’s start with the C of the initials CNN.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://i.stack.imgur.com/VC1TX.png" /></entry><entry><title type="html">Do que os políticos estão falando?</title><link href="http://localhost:4000/do-que-politicos-estao-falando/" rel="alternate" type="text/html" title="Do que os políticos estão falando?" /><published>2019-06-16T00:00:00-03:00</published><updated>2019-06-16T00:00:00-03:00</updated><id>http://localhost:4000/do-que-politicos-estao-falando</id><content type="html" xml:base="http://localhost:4000/do-que-politicos-estao-falando/">&lt;p&gt;Vivemos numa época em que é necessário prestar mais atenção ao que os políticos estão fazendo. Uma forma de se manter 
atualizado é monitorar o que eles dizem em seus discursos na Câmara.&lt;/p&gt;

&lt;p&gt;Para a nossa sorte, a &lt;a href=&quot;https://dadosabertos.camara.leg.br/swagger/api.html&quot;&gt;API  da câmara de deputados&lt;/a&gt; disponibiliza discursos dos deputados. Para examinar esses textos,  podemos usar a teoria de grafos, conforme &lt;a href=&quot;https://towardsdatascience.com/measuring-discourse-bias-using-text-network-analysis-9f251be5f6f3&quot;&gt;este artigo&lt;/a&gt; sobre análise de redes a fim de medir 
o viés em discursos.&lt;/p&gt;

&lt;p&gt;O código utilizado para esta análise pode ser encontrado neste &lt;a href=&quot;https://github.com/nymarya/political-speeches-networks&quot;&gt;repositório&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;dos-dados-aos-grafos&quot;&gt;Dos dados aos grafos&lt;/h2&gt;

&lt;p&gt;Tudo se inicia na importação dos dados. Com o auxílio da biblioteca &lt;a href=&quot;https://pypi.org/project/requests/&quot;&gt;requests&lt;/a&gt; do Python, podemos consultar os discursos de cada deputados
através da url &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;deputados\{id}\discursos&lt;/code&gt;. Os ids dos deputados, bem como seus respectivos partidos, foram recuperados consultando a url &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;deputados&lt;/code&gt;. Para definir um limite de 
discursos utilizados, filtramos apenas os que aconteceram este ano adicionando os parâmetros &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dataInicio=2019-01-01&lt;/code&gt; e&lt;br /&gt;
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dataFim=2019-06-11&lt;/code&gt;. Finalmente, ordenamos pelo horário de início do discurso. No fim, teremos uma consulta assim:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; query = 'https://dadosabertos.camara.leg.br/api/v2/deputados/'+str(dep[0])+\
           '/discursos?dataInicio=2019-01-01&amp;amp;dataFim=2019-06-11&amp;amp;ordenarPor=dataHoraInicio&amp;amp;ordem=ASC'
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;O retorno desta consulta é um json que contém a chave &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;transcricao&lt;/code&gt;. Seu valor é justamente o discurso em si.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;n&quot;&gt;speeches&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;

 &lt;span class=&quot;n&quot;&gt;total&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;deputies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
 &lt;span class=&quot;c1&quot;&gt;# Create a dictionary that contains
&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# id, speech, party, state
&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dep&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;deputies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

   &lt;span class=&quot;c1&quot;&gt;# Get all speechs given by the current deputy
&lt;/span&gt;   &lt;span class=&quot;n&quot;&gt;query&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'https://dadosabertos.camara.leg.br/api/v2/deputados/'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;\
           &lt;span class=&quot;s&quot;&gt;'/discursos?dataInicio=2019-01-01&amp;amp;dataFim=2019-06-11&amp;amp;ordenarPor=dataHoraInicio&amp;amp;ordem=ASC'&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;response&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;requests&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;speech_json&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;json&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

   &lt;span class=&quot;c1&quot;&gt;# Add each speech to the list
&lt;/span&gt;   &lt;span class=&quot;n&quot;&gt;speeches&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;speech&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'transcricao'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;speech&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;speech_json&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'dados'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Com isso, podemos montar um dataset que terá informações como id do deputado, discurso, sigla do partido e sigla do estado.&lt;/p&gt;

&lt;p&gt;Criado o dataset, é hora de tratar os dados. A característica mais importante a ser notada nos discursos é a de que todos tem 
uma introdução do locutor, como nos exemplos abaixo:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;O SR. ABOU ANNI (PSL - SP. Sem revisão do orador.) -&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;DISCURSO NA ÍNTEGRA ENCAMINHADO PELO SR. DEPUTADO BILAC PINTO.\r\n\r\n&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Para remover esses textos que não trazem relevância para o estudo, usamos algumas funções do &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pandas&lt;/code&gt;. Para o primeiro caso, 
a string é dividida pelo símbolo “-“ duas vezes, ignorando-se as duas primeiras substrings obtidas. Esse processo apaga as
strings que não seguem o primeiro padrão, sendo então necessário aplicar o tratamento do segundo padrão em uma cópia do dataset 
e unir ambos ao final. A segunda forma de introdução é removida ao dividir a string quando encontrar “\r\n\r\n” e manter 
apenas a segunda substring. Ao final, ainda é necessário remover todas as ocorrências de “\r”, “\n” e “-“ para a próxima 
etapa do desenvolvimento.&lt;/p&gt;

&lt;p&gt;A formação dos grafos se dá através do mapeamento das palavras usadas no discurso, sendo a frequência em que elas aparecem no 
texto o atributo que usaremos para medir sua importância. Cada nó é uma palavra e uma aresta 
entre duas palavras indica que elas aparecem no mesmo contexto.&lt;/p&gt;

&lt;p&gt;O que é contexto para nós? Bem, dada uma frase, cada palavra que a compõe é agrupada com suas vizinhas em grupos de 2 e 5 
palavras. Por exemplo, a frase&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Olhos de cigana oblíqua e dissimulada&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;seria dividida em&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;[Olhos de ], [de cigana], [cigana oblíqua], [oblíqua e], [e dissimulada], [ Olhos de cigana oblíqua e ], [de cigana oblíqua e dissimulada]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Esse método é o mesmo explicado no artigo mencionado na seção anterior e isso que tratamos como o contexto de uma palavra.&lt;/p&gt;

&lt;p&gt;Depois de divididas, são contadas quantas vezes cada conjunto ocorre no texto. Para isso, usamos a classe 
&lt;a href=&quot;https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;CountVectorizer&lt;/a&gt; do 
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;scikit-learn&lt;/code&gt;, que recebe uma expressão regular na forma &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;['[A-Za-z]+(?=\\s+)']&lt;/code&gt; para recuperar todas as palavras além dos espaços 
em branco que a seguem. Ao receber o parâmetro &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ngram_range=(2,5)&lt;/code&gt;, a própria função gera todas as combinações de palavras vizinhas 
de tamanho de 2 a 5 (sendo as de tamanho 3 e 4 removidas para formar o grafo nos próximos passos).&lt;/p&gt;

&lt;p&gt;Um parâmetro essencial que deve ser passado é o &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;stop_words&lt;/code&gt;, que define quais palavras devem ser ignoradas neste processo. 
Conjunções e artigos, por exemplo, são elementos que se repetem muito na língua portuguesa, o que traria uma frequência muito alta para estas palavras que 
não tem significado ao serem analisadas sozinhas. Sendo assim, muitos verbos, saudações, advérbios e outros elementos são adicionados 
nesta lista e não se tornam nós de um grafo.&lt;/p&gt;

&lt;p&gt;A classe é instanciada como abaixo:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;vec_alphanumeric&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CountVectorizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;token_pattern&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TOKENS_ALPHANUMERIC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                                   &lt;span class=&quot;n&quot;&gt;decode_error&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'replace'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                   &lt;span class=&quot;n&quot;&gt;stop_words&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;STOP_WORDS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ngram_range&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                                   &lt;span class=&quot;n&quot;&gt;encoding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'latin1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strip_accents&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'unicode'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;e ao acessar &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vec_alphanumeric.vocabulary_&lt;/code&gt; temos acesso a um dicionário no qual cada chave é um conjunto de palavras e 
 o seu valor representa o número de ocorrências no texto.&lt;/p&gt;

&lt;p&gt;O grafo é gerado usando a biblioteca &lt;a href=&quot;https://networkx.github.io&quot;&gt;NetworkX&lt;/a&gt;. O método responsável por sua criação recebe um par (chave, valor) do 
 dicionário criado pelo CountVectorizer e da chave extrai todas as palavras, 
 criando um nó para cada. Depois, forma pares dessas palavras e cria uma aresta para cada par com o peso sendo o valor recebido na entrada. 
 Se a aresta já existir, seu  peso é somado à frequência da frase.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;generate_graph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocabulary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

   &lt;span class=&quot;c1&quot;&gt;# Create a undirected graph
&lt;/span&gt;   &lt;span class=&quot;n&quot;&gt;G&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Graph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

   &lt;span class=&quot;c1&quot;&gt;# Iterate over each item of the vocabulary
&lt;/span&gt;   &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;phrase&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;frequency&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vocabulary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
     &lt;span class=&quot;c1&quot;&gt;# Get words in the phrase
&lt;/span&gt;     &lt;span class=&quot;n&quot;&gt;words&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;phrase&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

     &lt;span class=&quot;c1&quot;&gt;# Using only tokens of length 2 or 5
&lt;/span&gt;     &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;words&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;
       &lt;span class=&quot;k&quot;&gt;continue&lt;/span&gt;

     &lt;span class=&quot;n&quot;&gt;words_norm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;words&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;is_important&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
     &lt;span class=&quot;c1&quot;&gt;# Extract unique words in the phrase
&lt;/span&gt;     &lt;span class=&quot;n&quot;&gt;words_unique&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;words_norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

     &lt;span class=&quot;c1&quot;&gt;# Create a node if it does not exists already
&lt;/span&gt;     &lt;span class=&quot;n&quot;&gt;G&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_nodes_from&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;words_unique&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

     &lt;span class=&quot;c1&quot;&gt;# Form combinations of 2 from the words
&lt;/span&gt;     &lt;span class=&quot;c1&quot;&gt;# which will be a edge
&lt;/span&gt;     &lt;span class=&quot;n&quot;&gt;pair&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;combinations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;words_unique&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 

     &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word2&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;edge&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
       &lt;span class=&quot;c1&quot;&gt;# Increments weight of edge
&lt;/span&gt;       &lt;span class=&quot;c1&quot;&gt;# if it already exists
&lt;/span&gt;       &lt;span class=&quot;c1&quot;&gt;# Otherwise, create a new edge
&lt;/span&gt;       &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edge&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;G&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;edges&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
         &lt;span class=&quot;n&quot;&gt;G&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;edges&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'weight'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;frequency&lt;/span&gt;
       &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
         &lt;span class=&quot;n&quot;&gt;G&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_weighted_edges_from&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;frequency&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)])&lt;/span&gt;

   &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;G&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;A função &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;norm&lt;/code&gt; é usada para evitar repetições causadas por palavras no plural ou algumas conjugações de verbos.&lt;/p&gt;

&lt;p&gt;Com isso, obtemos nossos lindos grafos que serão analisados na próxima seção.&lt;/p&gt;

&lt;h2 id=&quot;ligando-os-pontos&quot;&gt;Ligando os pontos&lt;/h2&gt;

&lt;p&gt;Neste estudo, são usados todos os discursos de deputados de um mesmo partido. Os partidos gerados são PSL, PT, PDT e NOVO.&lt;/p&gt;

&lt;p&gt;Os conceitos utilizados para extrair informações são os de cliques e centralidade. Uma clique nada mais é do que um subconjunto 
de nós que são totalmente conectados entre si. É um conceito geralmente usado para representar um grupo (de pessoas) no qual 
todas se conhecem, que aqui usamos para detectar um grupo de palavras que aparecem no mesmo contexto.&lt;/p&gt;

&lt;p&gt;Já a centralidade é uma medida que ajuda a identificar nós importantes no grafo. Usamos a centralidade de grau, que mede o número de ligações (arestas) que incidem em um nó. Como estamos lidando com um grafo não direcionado, esse número é o mesmo número de arestas que estão ligadas ao nó. Esse indicador é usado para colorir cada nó dos grafos abaixos, gerados com a biblioteca &lt;a href=&quot;https://nxviz.readthedocs.io/en/latest/modules.html&quot;&gt;nxviz&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;psl&quot;&gt;PSL&lt;/h3&gt;

&lt;p&gt;A clique que obtemos com o grafo gerado com discursos de deputados do PSL comprova a intuição que temos 
ao pensar nesse partido. Segurança e polícia, que são temas que associamos às promessas dos 
candidatos, estão presentes.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/posts/graph_psl.png&quot; alt=&quot;PSL&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Uma pauta recorrente no congresso e cuja aparição era esperada é a 
reforma da previdência, que pode justificar o nó “reforma” neste grafo.&lt;/p&gt;

&lt;h3 id=&quot;pt&quot;&gt;PT&lt;/h3&gt;

&lt;p&gt;Já analisando o discurso do PT, na maior clique aparecem termos como educação, direito, social e saúde
que são diretamente ligados às principais pautas do partido.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/posts/graph_pt.png&quot; alt=&quot;PT&quot; /&gt;&lt;/p&gt;

&lt;p&gt;É esperado também a presença de “defesa”, visto que “em defesa da educação” é uma frase frequentemente 
usada para falar das greves e protestos contra os &lt;del&gt;cortes&lt;/del&gt; contigenciamentos das verbas para 
a educação. Isso também pode justificar a presença da palavra “ministro”, que foi muito criticado por falta de comunicação e por suas decisões.&lt;/p&gt;

&lt;p&gt;O tema de reforma da previdência também aparece neste grafo, o que não surpreende dada a posição 
forte do partido contra a mesma.&lt;/p&gt;

&lt;h3 id=&quot;novo&quot;&gt;NOVO&lt;/h3&gt;

&lt;p&gt;O grafo do NOVO difere dos demais, sem conter palavras comuns como “estado” e “governo”, 
mas apresenta “reforma” e “previdencia”, como seria esperado do partido que defende 
a reforma.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/posts/graph_novo.png&quot; alt=&quot;NOVO&quot; /&gt;&lt;/p&gt;

&lt;p&gt;É interessante ver que assuntos como renda e déficit são temas
que o deputados do NOVO mais gostam de citar e discutir.&lt;/p&gt;

&lt;h3 id=&quot;pdt&quot;&gt;PDT&lt;/h3&gt;

&lt;p&gt;A clique obtida a partir dos discursos do PDT  é a que mais se diferencia, 
sem conter nenhuma das palavras comuns aos anteriores.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/posts/graph_pdt.png&quot; alt=&quot;PDT&quot; /&gt;&lt;/p&gt;

&lt;p&gt;É curioso aparecerem nomes próprios como “flavio” e “geovania”, além dos termos como 
“discurso”, “pedido”, “comunicacao” e “registro”.&lt;/p&gt;

&lt;h2 id=&quot;considerações-finais&quot;&gt;Considerações finais&lt;/h2&gt;

&lt;p&gt;Como qualquer estudante de ciência da computação nota em algum ponto de sua trajetória acadêmica, os grafos possuem as mais variadas aplicações. Neste caso, serviram para trazer palavras-chave dos discursos dos deputados entre janeiro e junho de 2019.&lt;/p&gt;

&lt;p&gt;Com poucas métricas, já foi possível notar como os temas educação e reforma da previdência movimentaram a câmara nesses primeiros 6 meses, levando-se em consideração os 4 partidos analisados. Isso serve de estímulo para usar grafos, além de outras técnicas, para promover o monitoramento das ações dos políticos, incentivando, assim, a participação da população brasileira.&lt;/p&gt;

&lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://www.datacamp.com/courses/network-analysis-in-python-part-1&quot;&gt;Curso do Datacamp sobre análise de redes (inglês)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Clique_(graph_theory)&quot;&gt;Verbete sobre cliques (inglês)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://pt.wikipedia.org/wiki/Centralidade&quot;&gt;Verbete sobre centralidade&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Até a próxima!&lt;/p&gt;</content><author><name></name></author><category term="networks" /><category term="data science" /><category term="python" /><summary type="html">Vivemos numa época em que é necessário prestar mais atenção ao que os políticos estão fazendo. Uma forma de se manter atualizado é monitorar o que eles dizem em seus discursos na Câmara.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/images/posts/graph_psl.png" /></entry><entry><title type="html">Análise de gênero e raça na UFRN</title><link href="http://localhost:4000/analise-genero-cor-na-ufrn/" rel="alternate" type="text/html" title="Análise de gênero e raça na UFRN" /><published>2019-04-17T00:00:00-03:00</published><updated>2019-04-17T00:00:00-03:00</updated><id>http://localhost:4000/analise-genero-cor-na-ufrn</id><content type="html" xml:base="http://localhost:4000/analise-genero-cor-na-ufrn/">&lt;p&gt;Baseando-se em uma reportagem do Nexo Jornal que analisou a &lt;a href=&quot;https://www.nexojornal.com.br/grafico/2017/12/13/Gênero-e-raça-de-estudantes-do-ensino-superior-no-Brasil-por-curso-e-área&quot;&gt;distribuição de gênero e raça de estudantes do ensino superior no Brasil&lt;/a&gt;, realizada com os dados de 2016 do INEP, foi feito um estudo local utilizando &lt;a href=&quot;http:/dados.ufrn.br&quot;&gt;dados abertos da UFRN&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Uma parte da análise resume-se a identificar os padrões de estudantes com base nas áreas de conhecimento. Uma das bases usadas é a de discentes, que contém os dados do status (ativo, concluído, trancado) do curso do estudante, id do curso em que ele está matriculado, a matricula, a raça e o sexo.&lt;/p&gt;

&lt;p&gt;O outro dataset é o de cursos, que contém o nome do curso, a modalidade (graduação, doutorado, técnico) e a área de conhecimento na qual o curso se encaixa.&lt;/p&gt;

&lt;p&gt;Para visualizar os gráficos interativos, acesse &lt;a href=&quot;https://nbviewer.jupyter.org/github/nymarya/gender-and-race-ufrn/blob/master/genero_e_raca_todos.ipynb#Finalmente,-é-hora-de-juntar-tudo-e-plotar!&quot;&gt;este link&lt;/a&gt;. Lá, ao passar o mouse por cada ponto é possível visualizar o nome do curso, bem como a taxa de alunas mulheres e de alunos da raça determinada no gráfico. Também é possível usar o slider para mudar o ano analisado.&lt;/p&gt;

&lt;p&gt;Os demais estudos podem ser encontrados no &lt;a href=&quot;https://github.com/nymarya/gender-and-race-ufrn&quot;&gt;repositório&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;como-está-a-ufrn-hoje&quot;&gt;Como está a UFRN hoje?&lt;/h2&gt;

&lt;p&gt;O primeiro passo foi conferir o cenário atual (2019), com foco em ver quais áreas possuem maior proporção de alunas e de alunos de diferentes raças, além de atentar-se também a essas informações em relação ao curso de Tecnologia da Informação (BTI).&lt;/p&gt;

&lt;p&gt;No que diz respeito à presença feminina, os cursos de ciências da saúde e ciências sociais aplicadas são os que possuem mais de metade dos matriculados do sexo feminino. Desses, o que se encontra no topo é Serviço Social, tendo mulheres compondo 90% do total de estudantes.&lt;/p&gt;

&lt;p&gt;No curso de tecnologia da Informação, 9.74% dos alunos ingressantes eram mulheres.&lt;/p&gt;

&lt;p&gt;Como esperado, boa parte dos cursos de engenharia e de ciências exatas possuem menos de 50% de ingressantes do sexo feminino, o que pode ser constatado ao observar os pontos verde-claros e amarelos na metade inferior do gráfico abaixo:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/posts/brancos_2019.jpg&quot; alt=&quot;brancos_2019&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Além disso, boa parte dos cursos que possuem mais de 50% de alunos brancos (metade direita do gráfico) também são da área de engenharias.&lt;/p&gt;

&lt;p&gt;Em relação aos estudantes negros, o curso em que eles possuem a presença mais significativa é Teatro, onde foram 23% dos ingressantes. Em seguida, Música e Dança, respectivamente, foram os que mais receberam alunos negros em 2019. Também é interessante notar que esses cursos, bem como a maioria dos que tem apresentam uma presença de ingressantes negro superior a 10%, também possuem mais de 40% de mulheres.&lt;/p&gt;

&lt;p&gt;No BTI, estudantes negros foram 6.3% dos matriculados neste ano.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/posts/negros_2019.png&quot; alt=&quot;negros_2019&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Ao analisar os ingressantes de 2019 que se declaram como pardos, vemos que, dos (poucos) cursos nos quais esses alunos são pelo menos 50%, uma parte considerável são das áreas de ciências sociais aplicadas e ciências exatas e da terra.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/posts/pardos_2019.jpg&quot; alt=&quot;pardos_2019&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Uma observação interessante é a de que boa parte dos cursos nos quais ao menos 40% dos ingressantes eram mulheres também é vista uma presença considerável de pessoas de raças diferentes da branca. A relação onde essa percepção é mais evidente é a que compara a porcentagem de mulheres com a de alunos pardos, sendo ciências da saúde, ciências humanas e ciências sociais aplicadas as áreas onde esse comportamento é mais facilmente encontrado. Essa interseção de informações foi destacada na área cinza do gráfico abaixo:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/posts/pardos_2019_40.jpg&quot; alt=&quot;pardos_2019_40&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;o-que-mudou&quot;&gt;O que mudou?&lt;/h2&gt;

&lt;p&gt;Em 2012, pelos menos 40% dos alunos ingressante de muitos cursos se declaravam brancos. E isso acontecia em todas as áres de conhecimento, com exceção de ciências agrárias. Além disso, as alunas mulheres eram menos de um terço basicamente em algumas engenharias e cursos de ciências exatas e da terra. Em todos os cursos de exatas, mulheres são menos de 50% dos alunos matriculados.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/posts/brancos_2012.jpg&quot; alt=&quot;brancos_2012&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Já em 2016, pouco cursos possuíam mais de 40% de alunos brancos sendo matriculados, o que é bem contrastante com a situação de 2012. O que não supreende, porém, é que nesse grupo seleto os cursos de engenharia e ciências exatas se mostram mais presentes, comparando a outras áreas. O cenário em que engenharia e exatas são as áreas onde a proporção de mulheres é menor também não mudou muito, levando-se em consideração que neste momento possuem ainda menos alunas.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/posts/brancos_2016.jpg&quot; alt=&quot;brancos_2016&quot; /&gt;&lt;/p&gt;

&lt;p&gt;No ano de 2019, a distribuição de alunos brancos muda novamente, assumindo um padrão mais parecido com 2012, apesar de agora serem observados bem menos cursos com alunos brancos sendo 60% dos estudantes ingressantes.&lt;/p&gt;

&lt;p&gt;Tanto em 2019 como em 2016, apenas um curso de exatas possui uma turma de ingressantes com proporção de 50% ou mais de mulheres.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/posts/brancos_2019.jpg&quot; alt=&quot;brancos_2019&quot; /&gt;&lt;/p&gt;

&lt;p&gt;No curso de Tecnologia da Informação, cujos dados não existem em 2012 devido à data de criação do curso, a proporção de mulheres ingressantes varia entre 9% e 15% ao longo dos anos, com a taxa de 9.74% em 2019, como citado anteriormente.&lt;/p&gt;

&lt;h2 id=&quot;como-estamos-em-relação-ao-brasil&quot;&gt;Como estamos em relação ao Brasil?&lt;/h2&gt;

&lt;p&gt;Para poder comparar com os resultados encontrados pelo Nexo Jornal, foram analisados os dados de alunos que ingressaram em 2016 e estão com status de “ativo” ou “concluído”.&lt;/p&gt;

&lt;p&gt;O fato de os cursos de engenharias e exatas apresentarem poucos negros e poucas mulheres, por exemplo, estão de acordo com a situação observada no cenário nacional. No entanto, algo que chama a atenção é a presença considerável de negros em Gestão de Cooperativas.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/posts/negros_2016.png&quot; alt=&quot;negros_2016&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Enquanto na UFRN os cursos com mais alunos ingressantes indígenas são Ciências Autuariais, Dança e Engenharia Ambiental, no gráfico do Nexo não são destacados cursos das mesmas áreas. Apesar dessa diferença, a falta de indígenas na UFRN parece assumir a mesma proporção do cenário no restante do Brasil.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/posts/ind_2016.png&quot; alt=&quot;ind_2016&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;considerações-finais&quot;&gt;Considerações finais&lt;/h2&gt;

&lt;p&gt;Apesar de alguns avanços em relação à presença de alunas mulheres na UFRN, a falta de diversidade no que diz respeito a raça ainda é alarmante, principalmente pelo fato de o número de cursos com proporção maior de alunos brancos ter aumentado nos últimos anos, atingindo taxas próximas à época antes do sistema de cota ser implantado.&lt;/p&gt;

&lt;p&gt;Isso evidencia a importância de movimentos e comunidades como PyLadies, &lt;a href=&quot;https://www.instagram.com/wie.ufrn/?hl=pt-br&quot;&gt;Women in Engineering&lt;/a&gt;, &lt;a href=&quot;https://www.instagram.com/wtmnatal/&quot;&gt;Women Tech Makers&lt;/a&gt; e &lt;a href=&quot;https://afropython.org&quot;&gt;AfroPython&lt;/a&gt; em Natal, bem como outros que possam atrair pessoas ainda mais diversas para a UFRN, como aqueles de origem oriental e indígenas.&lt;/p&gt;

&lt;p&gt;Até a próxima!&lt;/p&gt;</content><author><name></name></author><category term="UFRN" /><category term="data science" /><category term="python" /><summary type="html">Baseando-se em uma reportagem do Nexo Jornal que analisou a distribuição de gênero e raça de estudantes do ensino superior no Brasil, realizada com os dados de 2016 do INEP, foi feito um estudo local utilizando dados abertos da UFRN.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://files.realpython.com/media/Intermediate_Watermarked.9f8c0a24bde7.jpg" /></entry><entry><title type="html">5 modos de carregar arquivos no Google Colab</title><link href="http://localhost:4000/5-modos-de-carregar-arquivos-no-google-colab/" rel="alternate" type="text/html" title="5 modos de carregar arquivos no Google Colab" /><published>2019-03-31T00:00:00-03:00</published><updated>2019-03-31T00:00:00-03:00</updated><id>http://localhost:4000/5-modos-de-carregar-arquivos-no-google-colab</id><content type="html" xml:base="http://localhost:4000/5-modos-de-carregar-arquivos-no-google-colab/">&lt;p&gt;O &lt;a href=&quot;https://colab.research.google.com&quot;&gt;Google Colab&lt;/a&gt; é uma ferramenta criada pela Google que permite que qualquer pessoa consiga produzir e rodar desde os notebooks IPython (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.ipynb&lt;/code&gt;) mais simples até treinar um modelo de &lt;em&gt;deep learning&lt;/em&gt; mesmo sem possuir uma GPU. É só usar sua conta Google e você terá acesso a 12GB de RAM, GPU/TPU (desde que não abuse e use para ganhar criptomoedas!), além de ter todo trabalho sincronizado automaticamente no Drive.&lt;/p&gt;

&lt;p&gt;Um dos primeiros problemas que aparecem ao usar o Colab é: como carregar arquivos nessa ferramenta, já que ele não tem acesso ao meu HD? Nesse post irei listar 5 jeitos de fazer isso, cada um com suas vantagens e desvantagens.&lt;/p&gt;

&lt;h3 id=&quot;1-usando-um-link&quot;&gt;1. Usando um link&lt;/h3&gt;

&lt;p&gt;Basta ver a documentação do método &lt;a href=&quot;https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_csv&lt;/code&gt;&lt;/a&gt; da biblioteca &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pandas&lt;/code&gt; para ver que uma url pode ser usada para carregar seu dataset. O jeito mais fácil de disponibilizar um link é fazendo o upload dos dados para o GitHub, mas nesse caso existe a limitação de que o arquivo deve ter menos de 25MB (um arquivo maior não pode ser mantido em seu repositório).&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;link&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Algumas alternativas ao GitHub como &lt;a href=&quot;https://gitlab.com&quot;&gt;GitLab&lt;/a&gt; e &lt;a href=&quot;http://bitbucket.org&quot;&gt;BitBucket&lt;/a&gt; possuem um limite mais flexível, o primeiro depende das configurações da sua organização e no segundo caso, o arquivo deve respeitar o limite de tamanho do repositório, que não pode ser maior que 2GB.&lt;/p&gt;

&lt;h3 id=&quot;2-fazendo-upload-de-sua-máquina-via-código&quot;&gt;2. Fazendo upload de sua máquina via código&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;Método apresentado no post do Towards Data Science: &lt;a href=&quot;https://towardsdatascience.com/3-ways-to-load-csv-files-into-colab-7c14fcbdcb92&quot;&gt;3 Ways to load csv into colab&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;O Colab possibilita que você insira arquivos do seu computador no notebook através do método &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;files&lt;/code&gt; do módulo &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;google.colab&lt;/code&gt;. Ao chamar &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;files.upload()&lt;/code&gt;, uma caixa de seleção vai aparecer como na imagem abaixo:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/posts/colab_upload_file_code.png&quot; alt=&quot;colab_upload_file_code&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Depois de escolher o arquivo, o objeto &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;uploaded&lt;/code&gt; acima, que é um dicionário com os dados em formato de bytes, pode ser manipulado para virar um objeto tratado pelo &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pandas&lt;/code&gt;. Para isso, usamos a biblioteca &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;io&lt;/code&gt;, como mostrado no exemplo abaixo.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;io&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;io&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BytesIO&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uploaded&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'file.csv'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Apesar de ser prático para um estudo rápido sobre um arquivo pequeno, por exemplo, essa &lt;em&gt;feature&lt;/em&gt; pode apresentar incompatibilidade com algumas versões de alguns navegadores, então nem sempre o método de leitura é aplicável.&lt;/p&gt;

&lt;h3 id=&quot;3-fazendo-upload-de-sua-máquina-via-colab&quot;&gt;3. Fazendo upload de sua máquina via colab&lt;/h3&gt;

&lt;p&gt;Uma alternativa relativamente recente, oferecida pelo próprio Colab, é usar a seção &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Files&lt;/code&gt; do menu lateral.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/posts/cola_files_tab.png&quot; alt=&quot;cola_files_tab&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Ao cliclar no botão &lt;strong&gt;UPLOAD&lt;/strong&gt;, uma janela de seleção semelhante à do item anterior será aberta. Depois do upload, o arquivo é listado nessa seção. Com 2 cliques é possível ainda visualizar (e filtrar!) o conteúdo do dataset.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/posts/colab_file_preview.png&quot; alt=&quot;colab_file_preview&quot; /&gt;&lt;/p&gt;

&lt;p&gt;No entanto, a maior mudança em relação ao &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;google.colab&lt;/code&gt; é que, além de apresentar maior compatibilidade com os navegadores, o arquivo não precisa ser convertido. Dá pra usar &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_csv&lt;/code&gt; passando o nome do arquivo e a extensão como parâmetros.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Os dois últimos métodos apresentados possuem algumas desvantagens em comum:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Toda vez que o notebook for aberto, o processo de upload precisa ser repetido ( o que prejudica muito a reproducibilidade do que você fez no notebook);&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Um arquivo grande vai demorar bastante, principalmente se a sua internet não for tão rápida.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Por isso, os dois se tornam mais úteis quando se quer fazer algo rápido e que não precisa ser compartilhado com outras pessoas.&lt;/p&gt;

&lt;h3 id=&quot;4-google-drive&quot;&gt;4. Google Drive&lt;/h3&gt;

&lt;p&gt;Ao abrir uma pasta no Google Drive, você pode observar que ela possui um &lt;em&gt;hash&lt;/em&gt;, um código em sua url. Bem, dá para usar esse link para ler os arquivos dessa pasta.&lt;/p&gt;

&lt;p&gt;O primeiro passo é a &lt;del&gt;aceitação&lt;/del&gt; autenticação. Ao rodar o código abaixo e clicar no link, você vai receber um &lt;em&gt;token&lt;/em&gt; para copiar e colar na caixa que é exibida no notebook.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;google.colab&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;auth&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;auth&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;authenticate_user&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;googleapiclient.discovery&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;build&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;drive_service&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;build&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'drive'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'v3'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;../images/posts/colab_drive_auth.png&quot; alt=&quot;colab_drive_auth&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Depois de se autenticar, você já pode usar o objeto &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;drive_service&lt;/code&gt; para consultar os arquivos. Com a API do Google Drive, é possível fazer a consulta especificando um parâmetro do método &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;files().list()&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;response&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;drive_service&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;files&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot; '&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;folder&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;' in parents&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;spaces&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'drive'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;fields&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'nextPageToken, files(id, name)'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Especificando &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;'&quot;+folder+&quot;' in parents&lt;/code&gt; são filtrados os arquivos que estão dentro da pasta &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;folder&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Depois de recuperados os arquivos e iterar sobre eles, vamos recuperar seus IDs e usar &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;files().get_media(fileId=id)&lt;/code&gt; para baixar o arquivo através da API. Depois disso, os bytes podem ser traduzidos e o arquivo tratado.&lt;/p&gt;

&lt;p&gt;Tudo isso deve ser feito dentro de um loop.&lt;/p&gt;

&lt;p&gt;Abaixo, um código completo com o exemplo de arquivos de imagens:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;page_token&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;response&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;drive_service&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;files&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;mimeType='image/png' and '&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;folder&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;' in parents&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                            &lt;span class=&quot;n&quot;&gt;spaces&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'drive'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                            &lt;span class=&quot;n&quot;&gt;fields&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'nextPageToken, files(id, name)'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                            &lt;span class=&quot;n&quot;&gt;pageToken&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;page_token&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;file&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'files'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]):&lt;/span&gt;
          &lt;span class=&quot;c1&quot;&gt;# Process change
&lt;/span&gt;          &lt;span class=&quot;n&quot;&gt;file_id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'id'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;request&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;drive_service&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;files&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_media&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fileId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;downloaded&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;io&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BytesIO&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;downloader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MediaIoBaseDownload&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;downloaded&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;request&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;done&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;done&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# _ is a placeholder for a progress object that we ignore.
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# (Our file is small, so we skip reporting progress.)
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;done&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;downloader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;next_chunk&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

          &lt;span class=&quot;n&quot;&gt;downloaded&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seek&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

           &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'.csv'&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'name'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;io&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BytesIO&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;downloaded&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()))&lt;/span&gt;

      &lt;span class=&quot;n&quot;&gt;page_token1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'nextPageToken'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;page_token1&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Com os arquivos recuperados, para usar o dataset, podemos passar o objeto para &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_csv&lt;/code&gt;. Por exemplo:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Com essa alternativa mais complexa, é preciso ter cuidado ao filtrar os arquivos, além de compartilhar toda a pasta com quem precisar reproduzir o estudo feito usando essa técnica.&lt;/p&gt;

&lt;h3 id=&quot;5-arquivos-compactados&quot;&gt;5. Arquivos compactados&lt;/h3&gt;

&lt;p&gt;O último método é na verdade um caso específico que pode acontecer ao usar qualquer um das opções anteriores.&lt;/p&gt;

&lt;p&gt;Alguns tipos de arquivos compactados não são lidos facilmente pelo &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pandas&lt;/code&gt;, como os disponilizados pelo IMDb. Para tratá-los, podemos usar a biblioteca &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gzip&lt;/code&gt; para descompactar e o método &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;urllib&lt;/code&gt; do módulo &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;six.moves&lt;/code&gt; para baixar o dataset. E &lt;em&gt;voilà&lt;/em&gt;:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;six.moves&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;urllib&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;gzip&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;handle&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;urllib&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;request&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;urlopen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'https://datasets.imdbws.com/title.basics.tsv.gz'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;#download
&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;file&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gzip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GzipFile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fileobj&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;handle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;#unzip
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;movies&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sep&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;considerações-finais&quot;&gt;Considerações finais&lt;/h2&gt;

&lt;p&gt;Cada método tem seu nível de dificuldade e uma limitação quanto ao tamanho da massa de dados que podem ser carregados de forma eficiente, cabe a cada um ver qual se encaixa melhor em cada situação.&lt;/p&gt;

&lt;p&gt;Nos links, referenciei uma alternativa ao passo 4 e alguns métodos para salvar arquivos a partir do Colab.&lt;/p&gt;

&lt;p&gt;Até a próxima!&lt;/p&gt;

&lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://developers.google.com/drive/api/v3/search-parameters&quot;&gt;API de busca de arquivos do Google Drive&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://colab.research.google.com/notebooks/io.ipynb&quot;&gt;Material do próprio Colab que contém maneiras de salvar arquivos&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><category term="colab" /><category term="data science" /><category term="python" /><summary type="html">O Google Colab é uma ferramenta criada pela Google que permite que qualquer pessoa consiga produzir e rodar desde os notebooks IPython (.ipynb) mais simples até treinar um modelo de deep learning mesmo sem possuir uma GPU. É só usar sua conta Google e você terá acesso a 12GB de RAM, GPU/TPU (desde que não abuse e use para ganhar criptomoedas!), além de ter todo trabalho sincronizado automaticamente no Drive.</summary></entry><entry><title type="html">O absurdo no teste de hipótese</title><link href="http://localhost:4000/o-absurdo-do-teste-de-hipotese/" rel="alternate" type="text/html" title="O absurdo no teste de hipótese" /><published>2018-12-01T00:00:00-02:00</published><updated>2018-12-01T00:00:00-02:00</updated><id>http://localhost:4000/o-absurdo-do-teste-de-hipotese</id><content type="html" xml:base="http://localhost:4000/o-absurdo-do-teste-de-hipotese/">&lt;p&gt;Uma das partes mais mágicas da Estatística é ser capaz de fazer inferência sobre alguma característica de uma população, enxergar padrões em certos comportamentos e assim conseguir tomar as decisões de forma consciente. Por exemplo, sabemos que o algoritmo &lt;em&gt;quick sort&lt;/em&gt; tem uma complexidade de O(\(n^2\)) quando o vetor já está ordenado. Mas será que mesmo assim vale a pena usar esse algoritmo no sistema? É comum que o algoritmo entre no pior caso, se escolhermos o pivot aleatoriamente?  Ao fazer a análise de complexidade média, vemos que a complexidade mais proável seria de O(n log n).&lt;/p&gt;

&lt;p&gt;No entanto, alguns casos de estudo não são tão previsíveis como este célebre algoritmo e nem sempre é possível fazer uma análise que englobe a totalidade dos dados. Imagine tentar descobrir as chances de um candidato ganhar uma eleição analisando toda a população ao invés de fazer inferências, como as pesquisas de intenção de voto: a coleta de dados se mostraria não só um processo extremamente custoso financeiramente como demasiado lento para uma análise onde o tempo é crucial.&lt;/p&gt;

&lt;h3 id=&quot;teste-de-hipótese&quot;&gt;Teste de hipótese&lt;/h3&gt;

&lt;p&gt;Vê-se então a utilidade da &lt;strong&gt;inferência estatística&lt;/strong&gt;, que baseia-se em, a partir de uma amostra, estimar algum parâmetro (média, por exemplo) envolvendo toda a população. Entretanto, ao formular uma hipótese estatística é preciso estar de posse de algum mecanismo que ofereça certa garantia de que a dedução feita ao analisar uma pequena parte do todo também vale no mundo real.&lt;/p&gt;

&lt;p&gt;Uma das formas de obter essa resposta é através do &lt;strong&gt;teste de hipótese&lt;/strong&gt;, cujo conceito foi forjado por &lt;a href=&quot;https://en.wikipedia.org/wiki/Ronald_Fisher&quot;&gt;Ronald Fisher&lt;/a&gt;, considerado por alguns o pai da estatística moderna. São formuladas duas hipóteses: \(H_0\), também conhecida como &lt;em&gt;hipótese nula&lt;/em&gt;; e \(H_1\), que recebe o nome de &lt;em&gt;hipótese alternativa&lt;/em&gt; e preferencialmente deve ser complementar à hipótese nula. O processo consiste em testar \(H_0\), avaliando a probabilidade dos dados observados ocorrerem assumindo que a hipótese nula seja válida.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;https://nymarya.github.io//images/posts/blue_screen.png&quot;&gt;&lt;img src=&quot;https://nymarya.github.io//images/posts/blue_screen.png&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;Testar uma hipótese supondo que ela é verdadeira e ainda por cima sem ter todos os dados? Parece contraditório.&lt;/p&gt;

&lt;h3 id=&quot;reductio-ad-absurdum&quot;&gt;Reductio ad absurdum&lt;/h3&gt;

&lt;p&gt;O argumento lógico por trás desse método é o &lt;strong&gt;reductio ad absurdum&lt;/strong&gt;. Ao supor uma proposição, é desenvolvido o pensamento até que o resultado seja algo tão absurdo que invalide a suposição inicial.&lt;/p&gt;

&lt;p&gt;Digamos que você quer provar que seu programa funciona, então essa seria sua hipótese. Intuivamente, sabemos que ele deve funcionar perfeitamente em diversas situações. Para isso, você o submete a uma bateria de testes mas observa que nem todos os casos são atentidos, encontrando uma contradição com sua premissa de que deveria rodar em todos os casos. Logo, você conclui que seu programa não está funcionando.&lt;/p&gt;

&lt;p&gt;Para o teste de hipótese, a linha de raciocínio começa assumindo que a hipótese nula é válida. Ao analisar os dados disponíveis é obtido o parâmetro.  Com base em um &lt;strong&gt;nível de significância&lt;/strong&gt;, é visto o quão o parâmetro se distancia de um valor razoável de acordo com um modelo, ou seja, se esse valor seria muito raro de se obter caso a hipótese nula fosse verdade. Então, ao obter um \(\alpha\) pequeno, chegamos a uma contradição, visto que ao assumir \(H_0\) como verdadeira é esperado um nível de significância alto. Se for o caso, é bem provável que nossa tese esteja errada, e podemos dizer que a rejeitamos.&lt;/p&gt;

&lt;p&gt;Ao utilizar a conclusão obtida pela técnica mencionada, podemos interpretar que o parâmetro ser obtido implica que \(H_1\) é válida.&lt;/p&gt;

&lt;p&gt;O valor que usamos como limiar para definir se rejeitamos a hipótese nula é p&amp;lt;0.05, ou seja: a probabilidade de ocorrência dos dados analisados uma vez que a hipótese nula seja válida deve ser menor que 5%.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Fun fact: o valor padrão de significância para um p-valor, p&amp;lt;0.05, foi apenas uma definição arbitrária do próprio Fisher em uma de suas publicações (que veio a ser adotado por toda a comunidade científica), desprovido de qualquer justificativa objetiva.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;atribuindo-valor-às-variáveis&quot;&gt;Atribuindo valor às variáveis&lt;/h3&gt;

&lt;p&gt;Enumerados os termos usados, um exemplo ajuda a visualizar melhor como esses dois conhecimentos se misturam.&lt;/p&gt;

&lt;p&gt;Digamos que nós queremos estudar o comportamento de acessos a um site que uma certa equipe é responsável. Depois de algum tempo, com base no retorno obtido das redes sociais, um dos integrantes acha que o percentual de usuário que possuem graduação é em média 60%, com 10 % de desvio padrão. Alguém da mesma equipe discorda, achando que a proporção deve ser diferente.&lt;/p&gt;

&lt;p&gt;Para saber quem está mais próximo do resultado real, façamos com que \(H_0\) represente a hipótese de que em média o percentual dos usuários que acessam o sistema possuem graduação seja diferente de 60% e \(H_1\), a afirmação que o percentual médio é igual a 60%.&lt;/p&gt;

&lt;p&gt;Existem dois modos de verificar se a hipótese nula deve ser rejeitada, depois de escolhido o nível de significância \(\alpha\), que geralmente é em torno de 0,05 e 0,1. Uma é usando &lt;em&gt;p&lt;/em&gt;-valor, onde o &lt;em&gt;p&lt;/em&gt;-valor menor que o nível de significância implica em rejeitar \(H_0\). Outra é calculando a região crítica, ou regra de decisão, que define um intervalo para o parâmetro \(\bar X\), no qual \(H_0\) será rejeitado. Ao calcular o parâmetro, é testado ele está contido na região crítica e, se for o caso, a tese é rejeitada.&lt;/p&gt;

&lt;p&gt;Vamos supor que ao fazer uma simulação dos usuários, foi obtido o histograma abaixo e que ao calcular o &lt;em&gt;p&lt;/em&gt;-valor, seu valor é de 0.03:&lt;/p&gt;

&lt;figure&gt;
 &lt;a href=&quot;https://nymarya.github.io//images/posts/simulation_site_access.png&quot;&gt;&lt;img src=&quot;https://nymarya.github.io//images/posts/simulation_site_access.png&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;Neste caso, \(H_0\) é rejeitado, ou seja, podemos dizer que há evidências de que o percentual médio dos usuários que acessam o sistema possuem graduação é 60%.&lt;/p&gt;

&lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://www.khanacademy.org/math/ap-statistics/tests-significance-ap/idea-significance-tests&quot;&gt;Aula do Khan Academy sobre testes de significância&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://philosophy.stackexchange.com/questions/561/what-is-the-difference-between-reductio-ad-absurdum-and-proof-by-contradiction&quot;&gt;Discussão sobre reductio ad absurdum e prova por contradição&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Null_hypothesis#Goals_of_null_hypothesis_tests&quot;&gt;Verbete sobre hipótese nula&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=bf3egy7TQ2Q&amp;amp;t=0s&amp;amp;list=PL8dPuuaLjXtNM_Y-bUAhblSAdWRnmBUcr&amp;amp;index=23&quot;&gt;Vídeo-aula sobre teste de hipótese do Crash Course Statistics&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://sites.google.com/site/sequiturquodlibet/courses/laac/dn-lcp/vi?authuser=0&quot;&gt;Estratégias de demonstração em Dedução Natural&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><category term="estatistica" /><category term="matematica" /><category term="reductio ad absurdum" /><summary type="html">Uma das partes mais mágicas da Estatística é ser capaz de fazer inferência sobre alguma característica de uma população, enxergar padrões em certos comportamentos e assim conseguir tomar as decisões de forma consciente. Por exemplo, sabemos que o algoritmo quick sort tem uma complexidade de O(\(n^2\)) quando o vetor já está ordenado. Mas será que mesmo assim vale a pena usar esse algoritmo no sistema? É comum que o algoritmo entre no pior caso, se escolhermos o pivot aleatoriamente? Ao fazer a análise de complexidade média, vemos que a complexidade mais proável seria de O(n log n).</summary></entry></feed>