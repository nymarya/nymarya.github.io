<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2019-11-15T19:20:48-03:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Mayra Azevedo</title><subtitle>Web development | Data science | Machine Learning | Computer science</subtitle><entry><title type="html">CNNS: The convolution</title><link href="http://localhost:4000/cnns-the-convolution/" rel="alternate" type="text/html" title="CNNS: The convolution" /><published>2019-11-15T00:00:00-03:00</published><updated>2019-11-15T00:00:00-03:00</updated><id>http://localhost:4000/cnns-the-convolution</id><content type="html" xml:base="http://localhost:4000/cnns-the-convolution/">&lt;p&gt;This post is the first of a series on deep learning, specifically Convolutional Neural Networks (CNNs), that consists of two theorical posts and one more practical, discussing a particular model. Let’s start with the C of the initials CNN.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Convolution&lt;/strong&gt; is a term used in mathematics for describing the operation on two functions that produces a third function expressing how the shape of one is modified by the other. I always remember one class in which the teacher explained this idea using a very simplistic example. Imagine that you are standing between two stages during a music festival: if you move closer to one or another, you will listen better to one song. If you stay in the middle, the signals are too mixed. This confusion is the convolution in action.&lt;/p&gt;

&lt;h2 id=&quot;talking-images&quot;&gt;Talking images&lt;/h2&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;https://media.giphy.com/media/8b5gDEqjO5BKM/giphy.gif&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;First, the basics of images. To the computer, an image is nothing but a matrix of integers. When the picture is b&amp;amp;w, each integer between 0 and 255 represents the luminosity of the pixel. There are two ways of representing RGB figures. The first is a group of 3 integers that composes a pixel, each value representing red, blue, or green value. On another approach, the image with dimensions mxnx3 has one layer for each color.&lt;/p&gt;

&lt;p&gt;In terms of image processing, convolute means executing multiple matrix multiplications between the matrix representing the image and the &lt;a href=&quot;https://en.wikipedia.org/wiki/Kernel_(image_processing)&quot;&gt;mask&lt;/a&gt;. Hence, we can apply several transformation filters, such as edge detection and blurring or sharpening effects.&lt;/p&gt;

&lt;h2 id=&quot;types-of-image-convolution&quot;&gt;Types of image convolution&lt;/h2&gt;

&lt;p&gt;Although a conventional matrix multiplication requires that the number of columns of the 1st matrix must equal the number of rows of the 2nd matrix, the convolution process has no such condition. The kernel’s dimensions don’t need to match the image, as the convolution is not the same as a traditional product. Instead, the operation is repeated successively across the picture, as if it would a sliding window moving over the image.&lt;/p&gt;

&lt;p&gt;Considering that the shapes do not match, there are several types of convolution that result in distinct dimensions. The &lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.convolve2d.html&quot;&gt;convolve&lt;/a&gt; method in scipy module presents three modes: &lt;em&gt;full, *with which at the end-points of the operation, the signals do not overlap completely, and boundary effects may occur; *same&lt;/em&gt;, in which the outcome is the same size as the image; and &lt;em&gt;valid&lt;/em&gt;, where the product consists only of those elements that do not rely on the zero-padding.&lt;/p&gt;

&lt;h2 id=&quot;talking-math&quot;&gt;Talking math&lt;/h2&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;https://media.giphy.com/media/26xBI73gWquCBBCDe/giphy.gif&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;The operation, as said before, is very similar to standard matrix multiplication. The differences begin with the size of the final matrix. When in the mode &lt;em&gt;full&lt;/em&gt;, the resulting matrix C has the size &lt;em&gt;m&lt;/em&gt; combines the size of the kernel matrix K and the image B. The equation below shows:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;m = |K| + |B| - 1&lt;/script&gt;

&lt;p&gt;The values of &lt;script type=&quot;math/tex&quot;&gt;C&lt;/script&gt; are obtained by multiplying K and B.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;C(i, j) = \sum_{p=0}^{i+1} \sum_{q=0}^{j+1} K(p,q) B(i - p + 1, j - q + 1)&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;j&lt;/script&gt; are some positions in &lt;script type=&quot;math/tex&quot;&gt;C&lt;/script&gt;, and the notation &lt;script type=&quot;math/tex&quot;&gt;M(a, b)&lt;/script&gt; denotes the element on the a-th row and b-th.&lt;/p&gt;

&lt;h2 id=&quot;convolute-and-learn&quot;&gt;Convolute and learn&lt;/h2&gt;

&lt;p&gt;The inspiration for inserting the idea of convolution to build a machine learning technique comes from a biological mechanism present in the brain of the mammals. The visual cortex contains groups of neurons called &lt;strong&gt;receptive fields&lt;/strong&gt;, that “&lt;a href=&quot;https://en.wikipedia.org/wiki/Receptive_field&quot;&gt;can elicit neuronal responses when stimulated&lt;/a&gt;”. Receptive fields overlap and repeat between neighboring cells, so they act as local filters over what they receive.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&quot;https://doi.org/10.1113%2Fjphysiol.1968.sp008455&quot;&gt;study&lt;/a&gt;, that brings information about that region, divides the cells into two types: &lt;em&gt;simple&lt;/em&gt;, that respond to specific patterns from within its receptive field; and &lt;em&gt;complex&lt;/em&gt;, that have larger receptive fields and are insensitive to the exact position of the pattern in the area.&lt;/p&gt;

&lt;h2 id=&quot;final-thoughts&quot;&gt;Final thoughts&lt;/h2&gt;

&lt;p&gt;It is important (and so interesting!) to learn about all the steps in the computational learning process, and it is especially powerful to understand the reason why the model was built in a particular way. In the next posts, we will continue to see some theory and then dissect and train a &lt;del&gt;really&lt;/del&gt; deep learning model.&lt;/p&gt;

&lt;h2 id=&quot;further-reading--references&quot;&gt;Further reading &amp;amp; references&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://docs.opencv.org/master/d2/d96/tutorial_py_table_of_contents_imgproc.html&quot;&gt;Image processing with OpenCV&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://cs231n.github.io/convolutional-networks/&quot;&gt;CS123N&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.nature.com/articles/s42003-018-0110-y&quot;&gt;Activations of DCNNs are aligned with gamma band activty of human visual cortex&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://books.google.com/books?id=8YrxWojxUA4C&amp;amp;pg=PA106&quot;&gt;Brain and the visual perception&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1363130&quot;&gt;Receptive fields of single neurones in the cat’s striate cortex&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><category term="networks" /><category term="data science" /><category term="python" /><summary type="html">This post is the first of a series on deep learning, specifically Convolutional Neural Networks (CNNs), that consists of two theorical posts and one more practical, discussing a particular model. Let’s start with the C of the initials CNN.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://i.stack.imgur.com/VC1TX.png" /></entry><entry><title type="html">Do que os políticos estão falando?</title><link href="http://localhost:4000/do-que-politicos-estao-falando/" rel="alternate" type="text/html" title="Do que os políticos estão falando?" /><published>2019-06-16T00:00:00-03:00</published><updated>2019-06-16T00:00:00-03:00</updated><id>http://localhost:4000/do-que-politicos-estao-falando</id><content type="html" xml:base="http://localhost:4000/do-que-politicos-estao-falando/">&lt;p&gt;Vivemos numa época em que é necessário prestar mais atenção ao que os políticos estão fazendo. Uma forma de se manter 
atualizado é monitorar o que eles dizem em seus discursos na Câmara.&lt;/p&gt;

&lt;p&gt;Para a nossa sorte, a &lt;a href=&quot;https://dadosabertos.camara.leg.br/swagger/api.html&quot;&gt;API  da câmara de deputados&lt;/a&gt; disponibiliza discursos dos deputados. Para usar esses textos,  podemos usar a teoria de grafos, conforme &lt;a href=&quot;https://towardsdatascience.com/measuring-discourse-bias-using-text-network-analysis-9f251be5f6f3&quot;&gt;este artigo&lt;/a&gt; sobre análise de redes a fim de medir 
viés em discursos.&lt;/p&gt;

&lt;p&gt;O código utilizado para esta análise pode ser encontrado neste &lt;a href=&quot;https://github.com/nymarya/political-speeches-networks&quot;&gt;repositório&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;dos-dados-aos-grafos&quot;&gt;Dos dados aos grafos&lt;/h2&gt;

&lt;p&gt;Tudo se inicia importação dos dados. Com o auxílio da biblioteca &lt;a href=&quot;https://pypi.org/project/requests/&quot;&gt;requests&lt;/a&gt; do Python, podemos consultar os discursos de cada deputados
através da url &lt;code class=&quot;highlighter-rouge&quot;&gt;deputados\{id}\discursos&lt;/code&gt;. Os ids dos deputados, bem como o partido e  foram recuperados consultando a url &lt;code class=&quot;highlighter-rouge&quot;&gt;deputados&lt;/code&gt;. Para definir um limite de 
discursos utilizados, filtramos apenas os que aconteceram este ano adicionando os parâmetros &lt;code class=&quot;highlighter-rouge&quot;&gt;dataInicio=2019-01-01&lt;/code&gt; e&lt;br /&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;dataFim=2019-06-11&lt;/code&gt;. Finalmente, ordenamos pelo horário de início do discurso. No fim, teremos uma consulta assim:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; query = 'https://dadosabertos.camara.leg.br/api/v2/deputados/'+str(dep[0])+\
           '/discursos?dataInicio=2019-01-01&amp;amp;dataFim=2019-06-11&amp;amp;ordenarPor=dataHoraInicio&amp;amp;ordem=ASC'
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;O retorno desta consulta é um json que contém a chave &lt;code class=&quot;highlighter-rouge&quot;&gt;transcricao&lt;/code&gt;. Seu valor é justamente o discurso em si.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;n&quot;&gt;speeches&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;

 &lt;span class=&quot;n&quot;&gt;total&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;deputies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
 &lt;span class=&quot;c1&quot;&gt;# Create a dictionary that contains
&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# id, speech, party, state
&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dep&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;deputies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

   &lt;span class=&quot;c1&quot;&gt;# Get all speechs given by the current deputy
&lt;/span&gt;   &lt;span class=&quot;n&quot;&gt;query&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'https://dadosabertos.camara.leg.br/api/v2/deputados/'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;\
           &lt;span class=&quot;s&quot;&gt;'/discursos?dataInicio=2019-01-01&amp;amp;dataFim=2019-06-11&amp;amp;ordenarPor=dataHoraInicio&amp;amp;ordem=ASC'&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;response&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;requests&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;speech_json&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;json&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

   &lt;span class=&quot;c1&quot;&gt;# Add each speech to the list
&lt;/span&gt;   &lt;span class=&quot;n&quot;&gt;speeches&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;speech&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'transcricao'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;speech&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;speech_json&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'dados'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Com isso, podemos montar um dataset que terá informações como id do deputado, discurso, sigla do partido e sigla do estado.&lt;/p&gt;

&lt;p&gt;Criado o dataset, é hora de tratar os dados. A característica mais importante a ser notada nos discursos, é a de que todos tem 
uma introdução do locutor, como nos exemplos abaixo:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;O SR. ABOU ANNI (PSL - SP. Sem revisão do orador.) -&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;DISCURSO NA ÍNTEGRA ENCAMINHADO PELO SR. DEPUTADO BILAC PINTO.\r\n\r\n&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Para remover esses textos que não trazem relevância para o estudo, usamos algumas funções do &lt;code class=&quot;highlighter-rouge&quot;&gt;pandas&lt;/code&gt;. Para o primeiro caso, 
a string é dividida pelo símbolo “-“ duas vezes, sendo as duas primeiras substrings obtida ignoradas. Esse processo apaga as
strings que não seguem o primeiro padrão, sendo então necessário aplicar o tratamento do segundo padrão em uma cópia do dataset 
e unindo ambos ao final. O segundo tipo de introdução é removida ao dividir a string quando encontrar “\r\n\r\n” e manter 
apenas a segunda substring. Ao final, ainda é necessário remover todas as ocorrências de “\r”, “\n” e “-“ para a próxima 
etapa do desenvolvimento.&lt;/p&gt;

&lt;p&gt;A formação dos grafos se dá através do mapeamento das palavras usadas no discurso, sendo a frequência em que elas aparecem no 
texto o atributo que usaremos para medir sua importância. Cada nó é uma palavra e uma aresta 
entre duas palavras indica que elas aparecem no mesmo contexto.&lt;/p&gt;

&lt;p&gt;O que é contexto para nós? Bem, dada uma frase, cada palavra que a compõe é agrupada com suas vizinhas em grupos de 2 e 5 
palavras. Por exemplo, a frase&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Olhos de cigana oblíqua e dissimulada&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;seria dividida em&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;[Olhos de ], [de cigana], [cigana oblíqua], [oblíqua e], [e dissimulada], [ Olhos de cigana oblíqua e ], [de cigana oblíqua e dissimulada]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Esse método é o mesmo explicado no artigo mencionado na seção anterior e isso que tratamos como o contexto de uma palavra.&lt;/p&gt;

&lt;p&gt;Depois de divididas, são contadas quantas vezes cada conjunto ocorre no texto. Para isso, usamos a classe 
&lt;a href=&quot;https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;CountVectorizer&lt;/a&gt; do 
&lt;code class=&quot;highlighter-rouge&quot;&gt;scikit-learn&lt;/code&gt;, que recebe uma expressão regular na forma &lt;code class=&quot;highlighter-rouge&quot;&gt;['[A-Za-z]+(?=\\s+)']&lt;/code&gt; para recuperar todas as palavras além dos espaços 
em branco que a seguem. Ao receber o parâmetro &lt;code class=&quot;highlighter-rouge&quot;&gt;ngram_range=(2,5)&lt;/code&gt;, a própria função gera todas as combinações de palavras vizinhas 
de tamanho de 2 a 5 (sendo as de tamanho 3 e 4 removidas para formar o grafo nos próximos passos).&lt;/p&gt;

&lt;p&gt;Um parâmetro essencial que deve ser passado é o &lt;code class=&quot;highlighter-rouge&quot;&gt;stop_words&lt;/code&gt;, que define quais palavras devem ser ignoradas neste processo. 
Conjunções e artigos, por exemplo, são elementos que se repetem muito na língua portuguesa, o que traria uma frequência muito alta para estas palavras que 
não tem significado ao serem analisadas sozinhas. Sendo assim, muitos verbos, saudações, advérbios e outros elementos são adicionados 
nesta lista e não se tornam nós de um grafo.&lt;/p&gt;

&lt;p&gt;A classe é instânciada como abaixo:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;vec_alphanumeric&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CountVectorizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;token_pattern&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TOKENS_ALPHANUMERIC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                                   &lt;span class=&quot;n&quot;&gt;decode_error&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'replace'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                   &lt;span class=&quot;n&quot;&gt;stop_words&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;STOP_WORDS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ngram_range&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                                   &lt;span class=&quot;n&quot;&gt;encoding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'latin1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strip_accents&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'unicode'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;e ao acessar &lt;code class=&quot;highlighter-rouge&quot;&gt;vec_alphanumeric.vocabulary_&lt;/code&gt; temos acesso a um dicionário no qual cada chave é um conjunto de palavras e 
 o seu valor representa o número de ocorrências no texto.&lt;/p&gt;

&lt;p&gt;O grafo é gerado usando a biblioteca &lt;a href=&quot;https://networkx.github.io&quot;&gt;NetworkX&lt;/a&gt;. O método responsável por sua criação recebe um par (chave, valor) do 
 dicionário criado pelo CountVectorizer e da chave extrai todas as palavras, 
 criando um nó para cada. Depois, forma pares dessas palavras e cria uma aresta para cada par com o peso sendo o valor recebido na entrada. 
 Se a aresta já existir, seu  peso é somado à frequência da frase.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;generate_graph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocabulary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

   &lt;span class=&quot;c1&quot;&gt;# Create a undirected graph
&lt;/span&gt;   &lt;span class=&quot;n&quot;&gt;G&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nx&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Graph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

   &lt;span class=&quot;c1&quot;&gt;# Iterate over each item of the vocabulary
&lt;/span&gt;   &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;phrase&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;frequency&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vocabulary&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
     &lt;span class=&quot;c1&quot;&gt;# Get words in the phrase
&lt;/span&gt;     &lt;span class=&quot;n&quot;&gt;words&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;phrase&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

     &lt;span class=&quot;c1&quot;&gt;# Using only tokens of length 2 or 5
&lt;/span&gt;     &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;words&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;
       &lt;span class=&quot;k&quot;&gt;continue&lt;/span&gt;

     &lt;span class=&quot;n&quot;&gt;words_norm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;words&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;is_important&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
     &lt;span class=&quot;c1&quot;&gt;# Extract unique words in the phrase
&lt;/span&gt;     &lt;span class=&quot;n&quot;&gt;words_unique&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;words_norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

     &lt;span class=&quot;c1&quot;&gt;# Create a node if it does not exists already
&lt;/span&gt;     &lt;span class=&quot;n&quot;&gt;G&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_nodes_from&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;words_unique&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

     &lt;span class=&quot;c1&quot;&gt;# Form combinations of 2 from the words
&lt;/span&gt;     &lt;span class=&quot;c1&quot;&gt;# which will be a edge
&lt;/span&gt;     &lt;span class=&quot;n&quot;&gt;pair&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;combinations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;words_unique&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 

     &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word2&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;edge&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
       &lt;span class=&quot;c1&quot;&gt;# Increments weight of edge
&lt;/span&gt;       &lt;span class=&quot;c1&quot;&gt;# if it already exists
&lt;/span&gt;       &lt;span class=&quot;c1&quot;&gt;# Otherwise, create a new edge
&lt;/span&gt;       &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edge&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;G&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;edges&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
         &lt;span class=&quot;n&quot;&gt;G&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;edges&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'weight'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;frequency&lt;/span&gt;
       &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
         &lt;span class=&quot;n&quot;&gt;G&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_weighted_edges_from&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;frequency&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)])&lt;/span&gt;

   &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;G&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;A função &lt;code class=&quot;highlighter-rouge&quot;&gt;norm&lt;/code&gt; é usada para evitar repetições causadas por palavras no plural ou algumas conjugações de verbos.&lt;/p&gt;

&lt;p&gt;Com isso, obtemos nossos lindos grafos que serão analisados na próxima seção.&lt;/p&gt;

&lt;h2 id=&quot;ligando-os-pontos&quot;&gt;Ligando os pontos&lt;/h2&gt;

&lt;p&gt;Neste estudo, são usados todos os discursos de deputados do mesmo partido. Os partidos gerados são PSL, PT, PDT e NOVO.&lt;/p&gt;

&lt;p&gt;Os conceitos utilizados para extrais informações são os de cliques e centralidade. Uma clique nada mais é do que um subconjunto 
de nós que são totalmente conectados entre si. É um conceito geralmente usado para representar um grupo (de pessoas) no qual 
todas se conhecem, que aqui usamos para detectar um grupo de palavras que aparecem no mesmo contexto.&lt;/p&gt;

&lt;p&gt;Já a centralidade é uma medida que ajuda a identificar nós importantes no grafo. Usamos a centralidade de grau, que mede o número de ligações (arestas) que incidem em um nó. Como estamos lidando com um grafo não direcionado, esse número é o mesmo número de arestas que estão ligadas ao nó. Esse indicador é usado para colorir cada nó dos grafos abaixos, gerados com a biblioteca &lt;a href=&quot;https://nxviz.readthedocs.io/en/latest/modules.html&quot;&gt;nxviz&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;psl&quot;&gt;PSL&lt;/h3&gt;

&lt;p&gt;A clique que obtemos com o grafo gerado com discursos de deputados do PSL comprova a intuição que temos 
ao pensar nesse partido. Segurança e polícia, que são temas que associamos às promessas dos 
candidatos, estão presentes.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/posts/graph_psl.png&quot; alt=&quot;PSL&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Uma pauta recorrente no congresso e cuja aparição era esperada é a 
reforma da previdência, que pode justificar o nó “reforma” neste grafo.&lt;/p&gt;

&lt;h3 id=&quot;pt&quot;&gt;PT&lt;/h3&gt;

&lt;p&gt;Já analisando o discurso do PT, na maior clique aparecem termos como educação, direito, social e saúde
que são diretamente ligados às principais pautas do partido.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/posts/graph_pt.png&quot; alt=&quot;PT&quot; /&gt;&lt;/p&gt;

&lt;p&gt;É esperado também a presença de “defesa”, visto que “em defesa da educação” é uma frase frequentemente 
usada para falar das greves e protestos contra os &lt;del&gt;cortes&lt;/del&gt; contigenciamentos das verbas para 
a educação. Isso também pode justificar a presença da palavra “ministro”, que foi muito criticado por falta de comunicação e por suas decisões.&lt;/p&gt;

&lt;p&gt;O tema de reforma da previdência também aparece neste grafo, o que não surpreende dada a posição 
forte do partido contra a mesma.&lt;/p&gt;

&lt;h3 id=&quot;novo&quot;&gt;NOVO&lt;/h3&gt;

&lt;p&gt;O grafo do NOVO difere dos demais, sem conter palavras comuns como “estado” e “governo”, 
mas apresenta “reforma” e “previdencia”, como seria esperado do partido que defende 
a reforma.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/posts/graph_novo.png&quot; alt=&quot;NOVO&quot; /&gt;&lt;/p&gt;

&lt;p&gt;É interessante ver que assuntos como renda e déficit são temas
que o deputados do NOVO mais gostam de citar e discutir.&lt;/p&gt;

&lt;h3 id=&quot;pdt&quot;&gt;PDT&lt;/h3&gt;

&lt;p&gt;A clique obtida a partir dos discursos do PDT  é a que mais se diferencia 
sem conter nenhuma das palavras comuns aos anteriores.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/posts/graph_pdt.png&quot; alt=&quot;PDT&quot; /&gt;&lt;/p&gt;

&lt;p&gt;É curioso aparecerem nomes próprios como “flavio” e “geovania”, além dos termos como 
“discurso”, “pedido”, “comunicacao” e “registro”.&lt;/p&gt;

&lt;h2 id=&quot;considerações-finais&quot;&gt;Considerações finais&lt;/h2&gt;

&lt;p&gt;Como qualquer estudante de ciência da computação nota em algum ponto de sua trajetória acadêmica, os grafos possuem as mais variadas aplicações. Neste caso, serviu para trazer palavras-chave dos discursos dos deputados entre janeiro e junho de 2019.&lt;/p&gt;

&lt;p&gt;Com poucas métricas, já foi possível notar como os temas educação e reforma da previdência movimentaram a câmara nesses primeiros 6 meses, levando-se em consideração os 4 partidos analisados. Isso serve de estímulo para usar grafos, além de outras técnicas, para promover o monitoramento das ações dos políticos, estimulando, assim, a participação da população brasileira.&lt;/p&gt;

&lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://www.datacamp.com/courses/network-analysis-in-python-part-1&quot;&gt;Curso do Datacamp sobre análise de redes (inglês)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Clique_(graph_theory)&quot;&gt;Verbete sobre cliques (inglês)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://pt.wikipedia.org/wiki/Centralidade&quot;&gt;Verbete sobre centralidade&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Até a próxima!&lt;/p&gt;</content><author><name></name></author><category term="networks" /><category term="data science" /><category term="python" /><summary type="html">Vivemos numa época em que é necessário prestar mais atenção ao que os políticos estão fazendo. Uma forma de se manter atualizado é monitorar o que eles dizem em seus discursos na Câmara.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://nymarya.github.io/images/posts/graph_psl.png" /></entry><entry><title type="html">Análise de gênero e raça na UFRN</title><link href="http://localhost:4000/analise-genero-cor-na-ufrn/" rel="alternate" type="text/html" title="Análise de gênero e raça na UFRN" /><published>2019-04-17T00:00:00-03:00</published><updated>2019-04-17T00:00:00-03:00</updated><id>http://localhost:4000/analise-genero-cor-na-ufrn</id><content type="html" xml:base="http://localhost:4000/analise-genero-cor-na-ufrn/">&lt;p&gt;Baseando-se em uma reportagem do Nexo Jornal que analisou a &lt;a href=&quot;https://www.nexojornal.com.br/grafico/2017/12/13/Gênero-e-raça-de-estudantes-do-ensino-superior-no-Brasil-por-curso-e-área&quot;&gt;distribuição de gênero e raça de estudantes do ensino superior no Brasil&lt;/a&gt;, realizada com os dados de 2016 do INEP, foi feito um estudo local utilizando &lt;a href=&quot;http:/dados.ufrn.br&quot;&gt;dados abertos da UFRN&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Uma parte da análise resume-se a identificar os padrões de estudantes com base nas áreas de conhecimento. Uma das bases usadas é a de discentes, que contém os dados do status (ativo, concluído, trancado) do curso do estudante, id do curso em que ele está matriculado, a matricula, a raça e o sexo.&lt;/p&gt;

&lt;p&gt;O outro dataset é o de cursos, que contém o nome do curso, a modalidade (graduação, doutorado, técnico) e a área de conhecimento na qual o curso se encaixa.&lt;/p&gt;

&lt;p&gt;Para visualizar os gráficos interativos, acesse &lt;a href=&quot;https://nbviewer.jupyter.org/github/nymarya/gender-and-race-ufrn/blob/master/genero_e_raca_todos.ipynb#Finalmente,-é-hora-de-juntar-tudo-e-plotar!&quot;&gt;este link&lt;/a&gt;. Lá, ao passar o mouse por cada ponto é possível visualizar o nome do curso, bem como a taxa de alunas mulheres e de alunos da raça determinada no gráfico. Também é possível usar o slider para mudar o ano analisado.&lt;/p&gt;

&lt;p&gt;Os demais estudos podem ser encontrados no &lt;a href=&quot;https://github.com/nymarya/gender-and-race-ufrn&quot;&gt;repositório&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;como-está-a-ufrn-hoje&quot;&gt;Como está a UFRN hoje?&lt;/h2&gt;

&lt;p&gt;O primeiro passo foi conferir o cenário atual (2019), com foco em ver quais áreas possuem maior proporção de alunas e de alunos de diferentes raças, além de atentar-se também a essas informações em relação ao curso de Tecnologia da Informação (BTI).&lt;/p&gt;

&lt;p&gt;No que diz respeito à presença feminina, os cursos de ciências da saúde e ciências sociais aplicadas são os que possuem mais de metade dos matriculados do sexo feminino. Desses, o que se encontra no topo é Serviço Social, tendo mulheres compondo 90% do total de estudantes.&lt;/p&gt;

&lt;p&gt;No curso de tecnologia da Informação, 9.74% dos alunos ingressantes eram mulheres.&lt;/p&gt;

&lt;p&gt;Como esperado, boa parte dos cursos de engenharia e de ciências exatas possuem menos de 50% de ingressantes do sexo feminino, o que pode ser constatado ao observar os pontos verde-claros e amarelos na metade inferior do gráfico abaixo:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/posts/brancos_2019.jpg&quot; alt=&quot;brancos_2019&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Além disso, boa parte dos cursos que possuem mais de 50% de alunos brancos (metade direita do gráfico) também são da área de engenharias.&lt;/p&gt;

&lt;p&gt;Em relação aos estudantes negros, o curso em que eles possuem a presença mais significativa é Teatro, onde foram 23% dos ingressantes. Em seguida, Música e Dança, respectivamente, foram os que mais receberam alunos negros em 2019. Também é interessante notar que esses cursos, bem como a maioria dos que tem apresentam uma presença de ingressantes negro superior a 10%, também possuem mais de 40% de mulheres.&lt;/p&gt;

&lt;p&gt;No BTI, estudantes negros foram 6.3% dos matriculados neste ano.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/posts/negros_2019.png&quot; alt=&quot;negros_2019&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Ao analisar os ingressantes de 2019 que se declaram como pardos, vemos que, dos (poucos) cursos nos quais esses alunos são pelo menos 50%, uma parte considerável são das áreas de ciências sociais aplicadas e ciências exatas e da terra.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/posts/pardos_2019.jpg&quot; alt=&quot;pardos_2019&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Uma observação interessante é a de que boa parte dos cursos nos quais ao menos 40% dos ingressantes eram mulheres também é vista uma presença considerável de pessoas de raças diferentes da branca. A relação onde essa percepção é mais evidente é a que compara a porcentagem de mulheres com a de alunos pardos, sendo ciências da saúde, ciências humanas e ciências sociais aplicadas as áreas onde esse comportamento é mais facilmente encontrado. Essa interseção de informações foi destacada na área cinza do gráfico abaixo:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/posts/pardos_2019_40.jpg&quot; alt=&quot;pardos_2019_40&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;o-que-mudou&quot;&gt;O que mudou?&lt;/h2&gt;

&lt;p&gt;Em 2012, pelos menos 40% dos alunos ingressante de muitos cursos se declaravam brancos. E isso acontecia em todas as áres de conhecimento, com exceção de ciências agrárias. Além disso, as alunas mulheres eram menos de um terço basicamente em algumas engenharias e cursos de ciências exatas e da terra. Em todos os cursos de exatas, mulheres são menos de 50% dos alunos matriculados.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/posts/brancos_2012.jpg&quot; alt=&quot;brancos_2012&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Já em 2016, pouco cursos possuíam mais de 40% de alunos brancos sendo matriculados, o que é bem contrastante com a situação de 2012. O que não supreende, porém, é que nesse grupo seleto os cursos de engenharia e ciências exatas se mostram mais presentes, comparando a outras áreas. O cenário em que engenharia e exatas são as áreas onde a proporção de mulheres é menor também não mudou muito, levando-se em consideração que neste momento possuem ainda menos alunas.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/posts/brancos_2016.jpg&quot; alt=&quot;brancos_2016&quot; /&gt;&lt;/p&gt;

&lt;p&gt;No ano de 2019, a distribuição de alunos brancos muda novamente, assumindo um padrão mais parecido com 2012, apesar de agora serem observados bem menos cursos com alunos brancos sendo 60% dos estudantes ingressantes.&lt;/p&gt;

&lt;p&gt;Tanto em 2019 como em 2016, apenas um curso de exatas possui uma turma de ingressantes com proporção de 50% ou mais de mulheres.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/posts/brancos_2019.jpg&quot; alt=&quot;brancos_2019&quot; /&gt;&lt;/p&gt;

&lt;p&gt;No curso de Tecnologia da Informação, cujos dados não existem em 2012 devido à data de criação do curso, a proporção de mulheres ingressantes varia entre 9% e 15% ao longo dos anos, com a taxa de 9.74% em 2019, como citado anteriormente.&lt;/p&gt;

&lt;h2 id=&quot;como-estamos-em-relação-ao-brasil&quot;&gt;Como estamos em relação ao Brasil?&lt;/h2&gt;

&lt;p&gt;Para poder comparar com os resultados encontrados pelo Nexo Jornal, foram analisados os dados de alunos que ingressaram em 2016 e estão com status de “ativo” ou “concluído”.&lt;/p&gt;

&lt;p&gt;O fato de os cursos de engenharias e exatas apresentarem poucos negros e poucas mulheres, por exemplo, estão de acordo com a situação observada no cenário nacional. No entanto, algo que chama a atenção é a presença considerável de negros em Gestão de Cooperativas.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/posts/negros_2016.png&quot; alt=&quot;negros_2016&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Enquanto na UFRN os cursos com mais alunos ingressantes indígenas são Ciências Autuariais, Dança e Engenharia Ambiental, no gráfico do Nexo não são destacados cursos das mesmas áreas. Apesar dessa diferença, a falta de indígenas na UFRN parece assumir a mesma proporção do cenário no restante do Brasil.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/posts/ind_2016.png&quot; alt=&quot;ind_2016&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;considerações-finais&quot;&gt;Considerações finais&lt;/h2&gt;

&lt;p&gt;Apesar de alguns avanços em relação à presença de alunas mulheres na UFRN, a falta de diversidade no que diz respeito a raça ainda é alarmante, principalmente pelo fato de o número de cursos com proporção maior de alunos brancos ter aumentado nos últimos anos, atingindo taxas próximas à época antes do sistema de cota ser implantado.&lt;/p&gt;

&lt;p&gt;Isso evidencia a importância de movimentos e comunidades como PyLadies, &lt;a href=&quot;https://www.instagram.com/wie.ufrn/?hl=pt-br&quot;&gt;Women in Engineering&lt;/a&gt;, &lt;a href=&quot;https://www.instagram.com/wtmnatal/&quot;&gt;Women Tech Makers&lt;/a&gt; e &lt;a href=&quot;https://afropython.org&quot;&gt;AfroPython&lt;/a&gt; em Natal, bem como outros que possam atrair pessoas ainda mais diversas para a UFRN, como aqueles de origem oriental e indígenas.&lt;/p&gt;

&lt;p&gt;Até a próxima!&lt;/p&gt;</content><author><name></name></author><category term="UFRN" /><category term="data science" /><category term="python" /><summary type="html">Baseando-se em uma reportagem do Nexo Jornal que analisou a distribuição de gênero e raça de estudantes do ensino superior no Brasil, realizada com os dados de 2016 do INEP, foi feito um estudo local utilizando dados abertos da UFRN.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://files.realpython.com/media/Intermediate_Watermarked.9f8c0a24bde7.jpg" /></entry><entry><title type="html">5 modos de carregar arquivos no Google Colab</title><link href="http://localhost:4000/5-modos-de-carregar-arquivos-no-google-colab/" rel="alternate" type="text/html" title="5 modos de carregar arquivos no Google Colab" /><published>2019-03-31T00:00:00-03:00</published><updated>2019-03-31T00:00:00-03:00</updated><id>http://localhost:4000/5-modos-de-carregar-arquivos-no-google-colab</id><content type="html" xml:base="http://localhost:4000/5-modos-de-carregar-arquivos-no-google-colab/">&lt;p&gt;O &lt;a href=&quot;https://colab.research.google.com&quot;&gt;Google Colab&lt;/a&gt; é uma ferramenta criada pela Google que permite que qualquer pessoa consiga produzir e rodar desde os notebooks IPython (&lt;code class=&quot;highlighter-rouge&quot;&gt;.ipynb&lt;/code&gt;) mais simples até treinar um modelo de &lt;em&gt;deep learning&lt;/em&gt; mesmo sem possuir uma GPU. É só usar sua conta Google e você terá acesso a 12GB de RAM, GPU/TPU (desde que não abuse e use para ganhar criptomoedas!), além de ter todo trabalho sincronizado automaticamente no Drive.&lt;/p&gt;

&lt;p&gt;Um dos primeiros problemas que aparecem ao usar o Colab é: como carregar arquivos nessa ferramenta, já que ele não tem acesso ao meu HD? Nesse post irei listar 5 jeitos de fazer isso, cada um com suas vantagens e desvantagens.&lt;/p&gt;

&lt;h3 id=&quot;1-usando-um-link&quot;&gt;1. Usando um link&lt;/h3&gt;

&lt;p&gt;Basta ver a documentação do método &lt;a href=&quot;https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;read_csv&lt;/code&gt;&lt;/a&gt; da biblioteca &lt;code class=&quot;highlighter-rouge&quot;&gt;pandas&lt;/code&gt; para ver que uma url pode ser usada para carregar seu dataset. O jeito mais fácil de disponibilizar um link é fazendo o upload dos dados para o GitHub, mas nesse caso existe a limitação de que o arquivo deve ter menos de 25MB (um arquivo maior não pode ser mantido em seu repositório).&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;link&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Algumas alternativas ao GitHub como &lt;a href=&quot;https://gitlab.com&quot;&gt;GitLab&lt;/a&gt; e &lt;a href=&quot;http://bitbucket.org&quot;&gt;BitBucket&lt;/a&gt; possuem um limite mais flexível, o primeiro depende das configurações da sua organização e no segundo caso, o arquivo deve respeitar o limite de tamanho do repositório, que não pode ser maior que 2GB.&lt;/p&gt;

&lt;h3 id=&quot;2-fazendo-upload-de-sua-máquina-via-código&quot;&gt;2. Fazendo upload de sua máquina via código&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;Método apresentado no post do Towards Data Science: &lt;a href=&quot;https://towardsdatascience.com/3-ways-to-load-csv-files-into-colab-7c14fcbdcb92&quot;&gt;3 Ways to load csv into colab&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;O Colab possibilita que você insira arquivos do seu computador no notebook através do método &lt;code class=&quot;highlighter-rouge&quot;&gt;files&lt;/code&gt; do módulo &lt;code class=&quot;highlighter-rouge&quot;&gt;google.colab&lt;/code&gt;. Ao chamar &lt;code class=&quot;highlighter-rouge&quot;&gt;files.upload()&lt;/code&gt;, uma caixa de seleção vai aparecer como na imagem abaixo:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/posts/colab_upload_file_code.png&quot; alt=&quot;colab_upload_file_code&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Depois de escolher o arquivo, o objeto &lt;code class=&quot;highlighter-rouge&quot;&gt;uploaded&lt;/code&gt; acima, que é um dicionário com os dados em formato de bytes, pode ser manipulado para virar um objeto tratado pelo &lt;code class=&quot;highlighter-rouge&quot;&gt;pandas&lt;/code&gt;. Para isso, usamos a biblioteca &lt;code class=&quot;highlighter-rouge&quot;&gt;io&lt;/code&gt;, como mostrado no exemplo abaixo.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;io&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;io&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BytesIO&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uploaded&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'file.csv'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Apesar de ser prático para um estudo rápido sobre um arquivo pequeno, por exemplo, essa &lt;em&gt;feature&lt;/em&gt; pode apresentar incompatibilidade com algumas versões de alguns navegadores, então nem sempre o método de leitura é aplicável.&lt;/p&gt;

&lt;h3 id=&quot;3-fazendo-upload-de-sua-máquina-via-colab&quot;&gt;3. Fazendo upload de sua máquina via colab&lt;/h3&gt;

&lt;p&gt;Uma alternativa relativamente recente, oferecida pelo próprio Colab, é usar a seção &lt;code class=&quot;highlighter-rouge&quot;&gt;Files&lt;/code&gt; do menu lateral.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/posts/cola_files_tab.png&quot; alt=&quot;cola_files_tab&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Ao cliclar no botão &lt;strong&gt;UPLOAD&lt;/strong&gt;, uma janela de seleção semelhante à do item anterior será aberta. Depois do upload, o arquivo é listado nessa seção. Com 2 cliques é possível ainda visualizar (e filtrar!) o conteúdo do dataset.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/posts/colab_file_preview.png&quot; alt=&quot;colab_file_preview&quot; /&gt;&lt;/p&gt;

&lt;p&gt;No entanto, a maior mudança em relação ao &lt;code class=&quot;highlighter-rouge&quot;&gt;google.colab&lt;/code&gt; é que, além de apresentar maior compatibilidade com os navegadores, o arquivo não precisa ser convertido. Dá pra usar &lt;code class=&quot;highlighter-rouge&quot;&gt;read_csv&lt;/code&gt; passando o nome do arquivo e a extensão como parâmetros.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Os dois últimos métodos apresentados possuem algumas desvantagens em comum:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Toda vez que o notebook for aberto, o processo de upload precisa ser repetido ( o que prejudica muito a reproducibilidade do que você fez no notebook);&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Um arquivo grande vai demorar bastante, principalmente se a sua internet não for tão rápida.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Por isso, os dois se tornam mais úteis quando se quer fazer algo rápido e que não precisa ser compartilhado com outras pessoas.&lt;/p&gt;

&lt;h3 id=&quot;4-google-drive&quot;&gt;4. Google Drive&lt;/h3&gt;

&lt;p&gt;Ao abrir uma pasta no Google Drive, você pode observar que ela possui um &lt;em&gt;hash&lt;/em&gt;, um código em sua url. Bem, dá para usar esse link para ler os arquivos dessa pasta.&lt;/p&gt;

&lt;p&gt;O primeiro passo é a &lt;del&gt;aceitação&lt;/del&gt; autenticação. Ao rodar o código abaixo e clicar no link, você vai receber um &lt;em&gt;token&lt;/em&gt; para copiar e colar na caixa que é exibida no notebook.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;google.colab&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;auth&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;auth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;authenticate_user&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;googleapiclient.discovery&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;build&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;drive_service&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;build&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'drive'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'v3'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;../images/posts/colab_drive_auth.png&quot; alt=&quot;colab_drive_auth&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Depois de se autenticar, você já pode usar o objeto &lt;code class=&quot;highlighter-rouge&quot;&gt;drive_service&lt;/code&gt; para consultar os arquivos. Com a API do Google Drive, é possível fazer a consulta especificando um parâmetro do método &lt;code class=&quot;highlighter-rouge&quot;&gt;files().list()&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;response&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;drive_service&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;files&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot; '&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;folder&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;' in parents&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;spaces&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'drive'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;fields&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'nextPageToken, files(id, name)'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Especificando &lt;code class=&quot;highlighter-rouge&quot;&gt;'&quot;+folder+&quot;' in parents&lt;/code&gt; são filtrados os arquivos que estão dentro da pasta &lt;code class=&quot;highlighter-rouge&quot;&gt;folder&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Depois de recuperados os arquivos e iterar sobre eles, vamos recuperar seus IDs e usar &lt;code class=&quot;highlighter-rouge&quot;&gt;files().get_media(fileId=id)&lt;/code&gt; para baixar o arquivo através da API. Depois disso, os bytes podem ser traduzidos e o arquivo tratado.&lt;/p&gt;

&lt;p&gt;Tudo isso deve ser feito dentro de um loop.&lt;/p&gt;

&lt;p&gt;Abaixo, um código completo com o exemplo de arquivos de imagens:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;page_token&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;response&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;drive_service&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;files&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;mimeType='image/png' and '&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;folder&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;' in parents&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                            &lt;span class=&quot;n&quot;&gt;spaces&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'drive'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                            &lt;span class=&quot;n&quot;&gt;fields&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'nextPageToken, files(id, name)'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                            &lt;span class=&quot;n&quot;&gt;pageToken&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;page_token&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;file&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'files'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]):&lt;/span&gt;
          &lt;span class=&quot;c1&quot;&gt;# Process change
&lt;/span&gt;          &lt;span class=&quot;n&quot;&gt;file_id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'id'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;request&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;drive_service&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;files&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_media&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fileId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;downloaded&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;io&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BytesIO&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;downloader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MediaIoBaseDownload&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;downloaded&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;request&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;done&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;done&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# _ is a placeholder for a progress object that we ignore.
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# (Our file is small, so we skip reporting progress.)
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;done&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;downloader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;next_chunk&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

          &lt;span class=&quot;n&quot;&gt;downloaded&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seek&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

           &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'.csv'&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'name'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;io&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BytesIO&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;downloaded&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()))&lt;/span&gt;

      &lt;span class=&quot;n&quot;&gt;page_token1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'nextPageToken'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;page_token1&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Com os arquivos recuperados, para usar o dataset, podemos passar o objeto para &lt;code class=&quot;highlighter-rouge&quot;&gt;read_csv&lt;/code&gt;. Por exemplo:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Com essa alternativa mais complexa, é preciso ter cuidado ao filtrar os arquivos, além de compartilhar toda a pasta com quem precisar reproduzir o estudo feito usando essa técnica.&lt;/p&gt;

&lt;h3 id=&quot;5-arquivos-compactados&quot;&gt;5. Arquivos compactados&lt;/h3&gt;

&lt;p&gt;O último método é na verdade um caso específico que pode acontecer ao usar qualquer um das opções anteriores.&lt;/p&gt;

&lt;p&gt;Alguns tipos de arquivos compactados não são lidos facilmente pelo &lt;code class=&quot;highlighter-rouge&quot;&gt;pandas&lt;/code&gt;, como os disponilizados pelo IMDb. Para tratá-los, podemos usar a biblioteca &lt;code class=&quot;highlighter-rouge&quot;&gt;gzip&lt;/code&gt; para descompactar e o método &lt;code class=&quot;highlighter-rouge&quot;&gt;urllib&lt;/code&gt; do módulo &lt;code class=&quot;highlighter-rouge&quot;&gt;six.moves&lt;/code&gt; para baixar o dataset. E &lt;em&gt;voilà&lt;/em&gt;:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;six.moves&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;urllib&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;gzip&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;handle&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;urllib&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;request&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;urlopen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'https://datasets.imdbws.com/title.basics.tsv.gz'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;#download
&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;file&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gzip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GzipFile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fileobj&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;handle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;#unzip
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;movies&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sep&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;considerações-finais&quot;&gt;Considerações finais&lt;/h2&gt;

&lt;p&gt;Cada método tem seu nível de dificuldade e uma limitação quanto ao tamanho da massa de dados que podem ser carregados de forma eficiente, cabe a cada um ver qual se encaixa melhor em cada situação.&lt;/p&gt;

&lt;p&gt;Nos links, referenciei uma alternativa ao passo 4 e alguns métodos para salvar arquivos a partir do Colab.&lt;/p&gt;

&lt;p&gt;Até a próxima!&lt;/p&gt;

&lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://developers.google.com/drive/api/v3/search-parameters&quot;&gt;API de busca de arquivos do Google Drive&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://colab.research.google.com/notebooks/io.ipynb&quot;&gt;Material do próprio Colab que contém maneiras de salvar arquivos&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><category term="colab" /><category term="data science" /><category term="python" /><summary type="html">O Google Colab é uma ferramenta criada pela Google que permite que qualquer pessoa consiga produzir e rodar desde os notebooks IPython (.ipynb) mais simples até treinar um modelo de deep learning mesmo sem possuir uma GPU. É só usar sua conta Google e você terá acesso a 12GB de RAM, GPU/TPU (desde que não abuse e use para ganhar criptomoedas!), além de ter todo trabalho sincronizado automaticamente no Drive.</summary></entry><entry><title type="html">O absurdo no teste de hipótese</title><link href="http://localhost:4000/o-absurdo-do-teste-de-hipotese/" rel="alternate" type="text/html" title="O absurdo no teste de hipótese" /><published>2018-12-01T00:00:00-02:00</published><updated>2018-12-01T00:00:00-02:00</updated><id>http://localhost:4000/o-absurdo-do-teste-de-hipotese</id><content type="html" xml:base="http://localhost:4000/o-absurdo-do-teste-de-hipotese/">&lt;p&gt;Uma das partes mais mágicas da Estatística é ser capaz de fazer inferência sobre alguma característica de uma população, enxergar padrões em certos comportamentos e assim conseguir tomar as decisões de forma consciente. Por exemplo, sabemos que o algoritmo &lt;em&gt;quick sort&lt;/em&gt; tem uma complexidade de O(&lt;script type=&quot;math/tex&quot;&gt;n^2&lt;/script&gt;) quando o vetor já está ordenado. Mas será que mesmo assim vale a pena usar esse algoritmo no sistema? É comum que o algoritmo entre no pior caso, se escolhermos o pivot aleatoriamente?  Ao fazer a análise de complexidade média, vemos que a complexidade mais proável seria de O(n log n).&lt;/p&gt;

&lt;p&gt;No entanto, alguns casos de estudo não são tão previsíveis como este célebre algoritmo e nem sempre é possível fazer uma análise que englobe a totalidade dos dados. Imagine tentar descobrir as chances de um candidato ganhar uma eleição analisando toda a população ao invés de fazer inferências, como as pesquisas de intenção de voto: a coleta de dados se mostraria não só um processo extremamente custoso financeiramente como demasiado lento para uma análise onde o tempo é crucial.&lt;/p&gt;

&lt;h3 id=&quot;teste-de-hipótese&quot;&gt;Teste de hipótese&lt;/h3&gt;

&lt;p&gt;Vê-se então a utilidade da &lt;strong&gt;inferência estatística&lt;/strong&gt;, que baseia-se em, a partir de uma amostra, estimar algum parâmetro (média, por exemplo) envolvendo toda a população. Entretanto, ao formular uma hipótese estatística é preciso estar de posse de algum mecanismo que ofereça certa garantia de que a dedução feita ao analisar uma pequena parte do todo também vale no mundo real.&lt;/p&gt;

&lt;p&gt;Uma das formas de obter essa resposta é através do &lt;strong&gt;teste de hipótese&lt;/strong&gt;, cujo conceito foi forjado por &lt;a href=&quot;https://en.wikipedia.org/wiki/Ronald_Fisher&quot;&gt;Ronald Fisher&lt;/a&gt;, considerado por alguns o pai da estatística moderna. São formuladas duas hipóteses: &lt;script type=&quot;math/tex&quot;&gt;H_0&lt;/script&gt;, também conhecida como &lt;em&gt;hipótese nula&lt;/em&gt;; e &lt;script type=&quot;math/tex&quot;&gt;H_1&lt;/script&gt;, que recebe o nome de &lt;em&gt;hipótese alternativa&lt;/em&gt; e preferencialmente deve ser complementar à hipótese nula. O processo consiste em testar &lt;script type=&quot;math/tex&quot;&gt;H_0&lt;/script&gt;, avaliando a probabilidade dos dados observados ocorrerem assumindo que a hipótese nula seja válida.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;https://nymarya.github.io//images/posts/blue_screen.png&quot;&gt;&lt;img src=&quot;https://nymarya.github.io//images/posts/blue_screen.png&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;Testar uma hipótese supondo que ela é verdadeira e ainda por cima sem ter todos os dados? Parece contraditório.&lt;/p&gt;

&lt;h3 id=&quot;reductio-ad-absurdum&quot;&gt;Reductio ad absurdum&lt;/h3&gt;

&lt;p&gt;O argumento lógico por trás desse método é o &lt;strong&gt;reductio ad absurdum&lt;/strong&gt;. Ao supor uma proposição, é desenvolvido o pensamento até que o resultado seja algo tão absurdo que invalide a suposição inicial.&lt;/p&gt;

&lt;p&gt;Digamos que você quer provar que seu programa funciona, então essa seria sua hipótese. Intuivamente, sabemos que ele deve funcionar perfeitamente em diversas situações. Para isso, você o submete a uma bateria de testes mas observa que nem todos os casos são atentidos, encontrando uma contradição com sua premissa de que deveria rodar em todos os casos. Logo, você conclui que seu programa não está funcionando.&lt;/p&gt;

&lt;p&gt;Para o teste de hipótese, a linha de raciocínio começa assumindo que a hipótese nula é válida. Ao analisar os dados disponíveis é obtido o parâmetro.  Com base em um &lt;strong&gt;nível de significância&lt;/strong&gt;, é visto o quão o parâmetro se distancia de um valor razoável de acordo com um modelo, ou seja, se esse valor seria muito raro de se obter caso a hipótese nula fosse verdade. Então, ao obter um &lt;script type=&quot;math/tex&quot;&gt;\alpha&lt;/script&gt; pequeno, chegamos a uma contradição, visto que ao assumir &lt;script type=&quot;math/tex&quot;&gt;H_0&lt;/script&gt; como verdadeira é esperado um nível de significância alto. Se for o caso, é bem provável que nossa tese esteja errada, e podemos dizer que a rejeitamos.&lt;/p&gt;

&lt;p&gt;Ao utilizar a conclusão obtida pela técnica mencionada, podemos interpretar que o parâmetro ser obtido implica que &lt;script type=&quot;math/tex&quot;&gt;H_1&lt;/script&gt; é válida.&lt;/p&gt;

&lt;p&gt;O valor que usamos como limiar para definir se rejeitamos a hipótese nula é p&amp;lt;0.05, ou seja: a probabilidade de ocorrência dos dados analisados uma vez que a hipótese nula seja válida deve ser menor que 5%.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Fun fact: o valor padrão de significância para um p-valor, p&amp;lt;0.05, foi apenas uma definição arbitrária do próprio Fisher em uma de suas publicações (que veio a ser adotado por toda a comunidade científica), desprovido de qualquer justificativa objetiva.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;atribuindo-valor-às-variáveis&quot;&gt;Atribuindo valor às variáveis&lt;/h3&gt;

&lt;p&gt;Enumerados os termos usados, um exemplo ajuda a visualizar melhor como esses dois conhecimentos se misturam.&lt;/p&gt;

&lt;p&gt;Digamos que nós queremos estudar o comportamento de acessos a um site que uma certa equipe é responsável. Depois de algum tempo, com base no retorno obtido das redes sociais, um dos integrantes acha que o percentual de usuário que possuem graduação é em média 60%, com 10 % de desvio padrão. Alguém da mesma equipe discorda, achando que a proporção deve ser diferente.&lt;/p&gt;

&lt;p&gt;Para saber quem está mais próximo do resultado real, façamos com que &lt;script type=&quot;math/tex&quot;&gt;H_0&lt;/script&gt; represente a hipótese de que em média o percentual dos usuários que acessam o sistema possuem graduação seja diferente de 60% e &lt;script type=&quot;math/tex&quot;&gt;H_1&lt;/script&gt;, a afirmação que o percentual médio é igual a 60%.&lt;/p&gt;

&lt;p&gt;Existem dois modos de verificar se a hipótese nula deve ser rejeitada, depois de escolhido o nível de significância &lt;script type=&quot;math/tex&quot;&gt;\alpha&lt;/script&gt;, que geralmente é em torno de 0,05 e 0,1. Uma é usando &lt;em&gt;p&lt;/em&gt;-valor, onde o &lt;em&gt;p&lt;/em&gt;-valor menor que o nível de significância implica em rejeitar &lt;script type=&quot;math/tex&quot;&gt;H_0&lt;/script&gt;. Outra é calculando a região crítica, ou regra de decisão, que define um intervalo para o parâmetro &lt;script type=&quot;math/tex&quot;&gt;\bar X&lt;/script&gt;, no qual &lt;script type=&quot;math/tex&quot;&gt;H_0&lt;/script&gt; será rejeitado. Ao calcular o parâmetro, é testado ele está contido na região crítica e, se for o caso, a tese é rejeitada.&lt;/p&gt;

&lt;p&gt;Vamos supor que ao fazer uma simulação dos usuários, foi obtido o histograma abaixo e que ao calcular o &lt;em&gt;p&lt;/em&gt;-valor, seu valor é de 0.03:&lt;/p&gt;

&lt;figure&gt;
 &lt;a href=&quot;https://nymarya.github.io//images/posts/simulation_site_access.png&quot;&gt;&lt;img src=&quot;https://nymarya.github.io//images/posts/simulation_site_access.png&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;Neste caso, &lt;script type=&quot;math/tex&quot;&gt;H_0&lt;/script&gt; é rejeitado, ou seja, podemos dizer que há evidências de que o percentual médio dos usuários que acessam o sistema possuem graduação é 60%.&lt;/p&gt;

&lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://www.khanacademy.org/math/ap-statistics/tests-significance-ap/idea-significance-tests&quot;&gt;Aula do Khan Academy sobre testes de significância&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://philosophy.stackexchange.com/questions/561/what-is-the-difference-between-reductio-ad-absurdum-and-proof-by-contradiction&quot;&gt;Discussão sobre reductio ad absurdum e prova por contradição&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Null_hypothesis#Goals_of_null_hypothesis_tests&quot;&gt;Verbete sobre hipótese nula&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=bf3egy7TQ2Q&amp;amp;t=0s&amp;amp;list=PL8dPuuaLjXtNM_Y-bUAhblSAdWRnmBUcr&amp;amp;index=23&quot;&gt;Vídeo-aula sobre teste de hipótese do Crash Course Statistics&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://sites.google.com/site/sequiturquodlibet/courses/laac/dn-lcp/vi?authuser=0&quot;&gt;Estratégias de demonstração em Dedução Natural&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><category term="estatistica" /><category term="matematica" /><category term="reductio ad absurdum" /><summary type="html">Uma das partes mais mágicas da Estatística é ser capaz de fazer inferência sobre alguma característica de uma população, enxergar padrões em certos comportamentos e assim conseguir tomar as decisões de forma consciente. Por exemplo, sabemos que o algoritmo quick sort tem uma complexidade de O() quando o vetor já está ordenado. Mas será que mesmo assim vale a pena usar esse algoritmo no sistema? É comum que o algoritmo entre no pior caso, se escolhermos o pivot aleatoriamente? Ao fazer a análise de complexidade média, vemos que a complexidade mais proável seria de O(n log n).</summary></entry></feed>