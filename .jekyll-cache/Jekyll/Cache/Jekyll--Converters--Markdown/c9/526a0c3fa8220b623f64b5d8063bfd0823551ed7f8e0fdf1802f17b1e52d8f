I"$<p>Para entrar na aceleração de Data Science do <a href="https://www.codenation.dev">Codenation</a>, os alunos tinham que predizer as notas de matemática do enem 2016. A “nota de corte” era 90% de acerto das notas e minha primeira submissão deve ter sido uns 91%. Na oitava semana veio o penúltimo desafio, que era o mesmo da inscrição. Então nada melhor do que aproveitar a oportunidade para refazer a solução e usar os novos conhecimentos para tentar melhorar a pontuação. O código está disponível <a href="https://github.com/nymarya/aceleradev/blob/master/enem-2">aqui</a>.</p>

<h3 id="o-feijão-com-arroz">O feijão com arroz</h3>

<p>Para os 90%, fui no básico: um modelo simples, um pré-processamento mais cuidadoso.</p>

<div align="center">
<img src="https://media.giphy.com/media/xT1XH14zaGcdC4j2bC/giphy.gif" />
</div>
<p><br /></p>

<p>O modelo escolhido foi o LinearRegression, com os parâmetros já pré-estabelecidos.</p>

<p>No tratamento, primeiro utilizei <a href="https://github.com/pandas-profiling/pandas-profiling">pandas-profiling</a> para ter uma visão geral do banco de treinamento. A ferramenta dá todas as estatísticas e já indica quais colunas tem correlação entre si. Retirei essas. Retirei também as que tinham 50% ou mais de valores nulos ou as colunas que tinham valor constante. Feita a separação entre features numericas e categoricas. As numéricas imputei os valores nulos com -1 e padronizei com <a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html">StandardScaler</a>. As categóricas imputei com a string “N/A” e usei o <a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html">OneHotEncoder</a>. Isso aumenta significativamente o numero de colunas, então tive que usar o TruncatedSVD para reduzir a dimensionalidade, que sem tratamento são meras 61462 features.</p>

<h3 id="digievoluindo-a-solução">Digievoluindo a solução</h3>

<div align="center">
<img src="https://media.giphy.com/media/nDb2WPoK832fK/giphy.gif" />
</div>
<p><br /></p>

<p>Feito o básico, resta fazer um trabalho mais rebuscado de engenharias de dados. A começar por mais uma etapa de limpeza de dados, dessa vez utilizando da <a href="https://github.com/nymarya/aceleradev/blob/master/enem-2/src/features/build_features.py#L110">correlação</a> para retirar algumas colunas. Para evitar redundância de dados, são retiradas as colunas numéricas que tem correlação maior que 0.5 ou menor que -0.2 com a coluna alvo <code class="language-plaintext highlighter-rouge">NU_NOTA_MT</code>.</p>

<p>Algumas coisas simples a serem testadas seria trocar o StandardScaler por outro normalizador como MinMaxScaler, RobustScaler, ou Normalizer. Essa mudança pode ser muito importante pelo fato de que o StandardScaler assume que seus dados seguem uma distribuição normal. De fato, no <a href="https://github.com/nymarya/aceleradev/blob/master/enem-4/">desafio</a> da semana seguinte, a mudança de StandardScaler para RobustScaler representou uma diferença de uns 5% no desempenho, um salto de 93% para 98%, mas neste caso o resultado não foi tão impactante.</p>

<p>Outra opção seria trocar o encoder por outro como CatBoost ou <a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html">OrdinalEncoder</a>, que, ao invés de cirar uma coluna para cada categoria como o OneHotEncoder, apenas tranforma as categorias na forma númerica. O primeiro não consegui inserir no código, mas o segundo foi testado e os resultados estão na tabela no  começo da próxima seção.</p>

<p>Também foram feitos experimentos com a redução de dimensionalidade testando <a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html">RFE</a>,  <a href="https://scikit-learn.org/stable/auto_examples/neighbors/plot_nca_dim_reduction.html">LDA, NCA</a> ou <a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html">SelectKBest</a>. O segundo e o terceiro não deram certo por não funcionarem com matriz esparsa (que é no que os dados se transformam após os passos anteriores). O primeiro, por ser recursivo, acaba sendo incompatível com o OneHotEncoder pela gigantesca quantidade de colunas geradas. O SelectKBest também apresentava um problema semelhante. Testei aplicando TruncatedSVD e depois outros para reduzir, mas não deu bom: muita demora, pouca mudança. As outras funções de redução mais lentas funcionaram com OrdinalEncoder por não aumentar a cardinalidade das colunas.</p>

<p>Por fim, em relação aos modelos de regressão, foram testados LinearRegression, <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.TheilSenRegressor.html">TheisenRegressor</a> e <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html">RandomForestRegressor</a> e <a href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html">DecisionTreeRegressor</a>.</p>

<h3 id="avaliando-as-avaliações">Avaliando as avaliações</h3>

<table>
  <thead>
    <tr>
      <th>Correlação</th>
      <th>Scaler/Normalizer</th>
      <th>Encoder</th>
      <th>Reduce_dim</th>
      <th>Model</th>
      <th>Score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Sim</td>
      <td>Normalizer</td>
      <td>OneHotEncoder</td>
      <td>SelectKBest(30)</td>
      <td>LR</td>
      <td>91.72</td>
    </tr>
    <tr>
      <td>Sim</td>
      <td>RobustScaler</td>
      <td>OrdinalEncoder</td>
      <td>SelectKBest(30)</td>
      <td>LR</td>
      <td>93.28</td>
    </tr>
    <tr>
      <td>Sim</td>
      <td>RobustScaler</td>
      <td>OneHotEncoder</td>
      <td>SelectKBest(10)</td>
      <td>LR</td>
      <td>93.25</td>
    </tr>
    <tr>
      <td>Sim</td>
      <td>RobustScaler</td>
      <td>OneHotEncoder</td>
      <td>SelectKBest(50)</td>
      <td>TheisenRegressor</td>
      <td>92.52</td>
    </tr>
    <tr>
      <td>Sim</td>
      <td>QuantileTransformer</td>
      <td>OneHotEncoder</td>
      <td>SelectKBest(50)</td>
      <td>TheisenRegressor</td>
      <td>93.07</td>
    </tr>
    <tr>
      <td>Não</td>
      <td>QuantileTransformer</td>
      <td>OneHotEncoder</td>
      <td>SelectKBest(50)</td>
      <td>TheisenRegressor</td>
      <td>93.36</td>
    </tr>
    <tr>
      <td>Não</td>
      <td>RobustScaler</td>
      <td>OneHotEncoder</td>
      <td>SelectKBest(50)</td>
      <td>LR</td>
      <td>93.37</td>
    </tr>
    <tr>
      <td>Não</td>
      <td>RobustScaler</td>
      <td>OneHotEncoder</td>
      <td>RFE(50, LR)</td>
      <td>LR</td>
      <td>93.31</td>
    </tr>
    <tr>
      <td>Não</td>
      <td>RobustScaler</td>
      <td>OneHotEncoder</td>
      <td>RFE(30, LR)</td>
      <td>LR</td>
      <td>93.36</td>
    </tr>
    <tr>
      <td>Não</td>
      <td>RobustScaler</td>
      <td>OneHotEncoder</td>
      <td>RFE(30, SVR)</td>
      <td>LR</td>
      <td>93.37</td>
    </tr>
    <tr>
      <td>Não</td>
      <td>RobustScaler</td>
      <td>OneHotEncoder</td>
      <td>SelectKBest(50)</td>
      <td>RandomForest</td>
      <td>93.5</td>
    </tr>
    <tr>
      <td>Não</td>
      <td>RobustScaler</td>
      <td>OneHotEncoder</td>
      <td>SelectKBest(50)</td>
      <td>RandomForest(n_estimator=50)</td>
      <td>93.56</td>
    </tr>
    <tr>
      <td>Não</td>
      <td>RobustScaler</td>
      <td>OneHotEncoder</td>
      <td>SelectKBest(50)</td>
      <td>RandomForest( n_estimators=50, max_depth=4, min_samples_split=4,                                   max_features=0.5)</td>
      <td>93.64</td>
    </tr>
    <tr>
      <td>Não</td>
      <td>RobustScaler</td>
      <td>OneHotEncoder</td>
      <td>SelectKBest(50)</td>
      <td>DecisionTreeRegressor</td>
      <td>91</td>
    </tr>
  </tbody>
</table>

<p>Tirando o primeiro, todos os algoritmos tem algum fator aleatório, o que quer dizer que para ter uma noção boa do resultado, tem que ser feitas várias execuções para analisar estatisticamente os resultados. Por exemplo, o melhor resultado encontrado foi com RandomForestRegressor, mas ao rodar várias vezes o índice não foi observado novamente muito menos melhorou. De forma geral, os métodos mais rebuscados não tiveram uma diferença tão grande em relação à boa e velha regressão linear.</p>

<p>Concluindo, numa situação de vida real certamente o mais vantajoso, dentre os cenários vistos, seria não sair do feijão com arroz (regressão linear), apenas adicionar umas hortaliças para incrementar o PF (investir no tratamento dos dados).</p>

<blockquote>
  <p>Disclaimer: os pontos mais importantes do curso, pessoalmente falando, foram as aulas sobre metodologia científica e estatística, coisas que não foram abordadas nesse post.</p>
</blockquote>

<p>Enfim, é isto. Até mais!</p>

<h2 id="links-úteis">Links úteis</h2>

<p><a href="https://benalexkeen.com/feature-scaling-with-scikit-learn/">Feature Scaling with scikit-learn</a></p>

<p><a href="https://github.com/nymarya/aceleradev/tree/master/enem-2">Repositório</a></p>
:ET