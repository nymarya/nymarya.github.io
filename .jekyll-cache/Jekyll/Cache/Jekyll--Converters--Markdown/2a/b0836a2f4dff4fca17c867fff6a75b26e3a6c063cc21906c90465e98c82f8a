I"¡I<p>Vivemos numa √©poca em que √© necess√°rio prestar mais aten√ß√£o ao que os pol√≠ticos est√£o fazendo. Uma forma de se manter 
atualizado √© monitorar o que eles dizem em seus discursos na C√¢mara.</p>

<p>Para a nossa sorte, a <a href="https://dadosabertos.camara.leg.br/swagger/api.html">API  da c√¢mara de deputados</a> disponibiliza discursos dos deputados. Para examinar esses textos,  podemos usar a teoria de grafos, conforme <a href="https://towardsdatascience.com/measuring-discourse-bias-using-text-network-analysis-9f251be5f6f3">este artigo</a> sobre an√°lise de redes a fim de medir 
o vi√©s em discursos.</p>

<p>O c√≥digo utilizado para esta an√°lise pode ser encontrado neste <a href="https://github.com/nymarya/political-speeches-networks">reposit√≥rio</a>.</p>

<h2 id="dos-dados-aos-grafos">Dos dados aos grafos</h2>

<p>Tudo se inicia na importa√ß√£o dos dados. Com o aux√≠lio da biblioteca <a href="https://pypi.org/project/requests/">requests</a> do Python, podemos consultar os discursos de cada deputados
atrav√©s da url <code class="language-plaintext highlighter-rouge">deputados\{id}\discursos</code>. Os ids dos deputados, bem como seus respectivos partidos, foram recuperados consultando a url <code class="language-plaintext highlighter-rouge">deputados</code>. Para definir um limite de 
discursos utilizados, filtramos apenas os que aconteceram este ano adicionando os par√¢metros <code class="language-plaintext highlighter-rouge">dataInicio=2019-01-01</code> e<br />
<code class="language-plaintext highlighter-rouge">dataFim=2019-06-11</code>. Finalmente, ordenamos pelo hor√°rio de in√≠cio do discurso. No fim, teremos uma consulta assim:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> query = 'https://dadosabertos.camara.leg.br/api/v2/deputados/'+str(dep[0])+\
           '/discursos?dataInicio=2019-01-01&amp;dataFim=2019-06-11&amp;ordenarPor=dataHoraInicio&amp;ordem=ASC'
</code></pre></div></div>

<p>O retorno desta consulta √© um json que cont√©m a chave <code class="language-plaintext highlighter-rouge">transcricao</code>. Seu valor √© justamente o discurso em si.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="n">speeches</span> <span class="o">=</span> <span class="p">[]</span>

 <span class="n">total</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">deputies</span><span class="p">)</span>
 <span class="c1"># Create a dictionary that contains
</span> <span class="c1"># id, speech, party, state
</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">dep</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">deputies</span><span class="p">):</span>

   <span class="c1"># Get all speechs given by the current deputy
</span>   <span class="n">query</span> <span class="o">=</span> <span class="s">'https://dadosabertos.camara.leg.br/api/v2/deputados/'</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">dep</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">+</span>\
           <span class="s">'/discursos?dataInicio=2019-01-01&amp;dataFim=2019-06-11&amp;ordenarPor=dataHoraInicio&amp;ordem=ASC'</span>
   <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
   <span class="n">speech_json</span> <span class="o">=</span> <span class="n">response</span><span class="p">.</span><span class="n">json</span><span class="p">()</span>

   <span class="c1"># Add each speech to the list
</span>   <span class="n">speeches</span> <span class="o">+=</span> <span class="p">[[</span> <span class="n">dep</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">speech</span><span class="p">[</span><span class="s">'transcricao'</span><span class="p">],</span> <span class="n">dep</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">dep</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="p">]</span> <span class="k">for</span> <span class="n">speech</span> <span class="ow">in</span> <span class="n">speech_json</span><span class="p">[</span><span class="s">'dados'</span><span class="p">]]</span>
</code></pre></div></div>

<p>Com isso, podemos montar um dataset que ter√° informa√ß√µes como id do deputado, discurso, sigla do partido e sigla do estado.</p>

<p>Criado o dataset, √© hora de tratar os dados. A caracter√≠stica mais importante a ser notada nos discursos √© a de que todos tem 
uma introdu√ß√£o do locutor, como nos exemplos abaixo:</p>

<blockquote>
  <p>O SR. ABOU ANNI (PSL - SP. Sem revis√£o do orador.) -</p>
</blockquote>

<blockquote>
  <p>DISCURSO NA √çNTEGRA ENCAMINHADO PELO SR. DEPUTADO BILAC PINTO.\r\n\r\n</p>
</blockquote>

<p>Para remover esses textos que n√£o trazem relev√¢ncia para o estudo, usamos algumas fun√ß√µes do <code class="language-plaintext highlighter-rouge">pandas</code>. Para o primeiro caso, 
a string √© dividida pelo s√≠mbolo ‚Äú-‚Äú duas vezes, ignorando-se as duas primeiras substrings obtidas. Esse processo apaga as
strings que n√£o seguem o primeiro padr√£o, sendo ent√£o necess√°rio aplicar o tratamento do segundo padr√£o em uma c√≥pia do dataset 
e unir ambos ao final. A segunda forma de introdu√ß√£o √© removida ao dividir a string quando encontrar ‚Äú\r\n\r\n‚Äù e manter 
apenas a segunda substring. Ao final, ainda √© necess√°rio remover todas as ocorr√™ncias de ‚Äú\r‚Äù, ‚Äú\n‚Äù e ‚Äú-‚Äú para a pr√≥xima 
etapa do desenvolvimento.</p>

<p>A forma√ß√£o dos grafos se d√° atrav√©s do mapeamento das palavras usadas no discurso, sendo a frequ√™ncia em que elas aparecem no 
texto o atributo que usaremos para medir sua import√¢ncia. Cada n√≥ √© uma palavra e uma aresta 
entre duas palavras indica que elas aparecem no mesmo contexto.</p>

<p>O que √© contexto para n√≥s? Bem, dada uma frase, cada palavra que a comp√µe √© agrupada com suas vizinhas em grupos de 2 e 5 
palavras. Por exemplo, a frase</p>

<blockquote>
  <p>Olhos de cigana obl√≠qua e dissimulada</p>
</blockquote>

<p>seria dividida em</p>

<blockquote>
  <p>[Olhos de ], [de cigana], [cigana obl√≠qua], [obl√≠qua e], [e dissimulada], [ Olhos de cigana obl√≠qua e ], [de cigana obl√≠qua e dissimulada]</p>
</blockquote>

<p>Esse m√©todo √© o mesmo explicado no artigo mencionado na se√ß√£o anterior e isso que tratamos como o contexto de uma palavra.</p>

<p>Depois de divididas, s√£o contadas quantas vezes cada conjunto ocorre no texto. Para isso, usamos a classe 
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer">CountVectorizer</a> do 
<code class="language-plaintext highlighter-rouge">scikit-learn</code>, que recebe uma express√£o regular na forma <code class="language-plaintext highlighter-rouge">['[A-Za-z]+(?=\\s+)']</code> para recuperar todas as palavras al√©m dos espa√ßos 
em branco que a seguem. Ao receber o par√¢metro <code class="language-plaintext highlighter-rouge">ngram_range=(2,5)</code>, a pr√≥pria fun√ß√£o gera todas as combina√ß√µes de palavras vizinhas 
de tamanho de 2 a 5 (sendo as de tamanho 3 e 4 removidas para formar o grafo nos pr√≥ximos passos).</p>

<p>Um par√¢metro essencial que deve ser passado √© o <code class="language-plaintext highlighter-rouge">stop_words</code>, que define quais palavras devem ser ignoradas neste processo. 
Conjun√ß√µes e artigos, por exemplo, s√£o elementos que se repetem muito na l√≠ngua portuguesa, o que traria uma frequ√™ncia muito alta para estas palavras que 
n√£o tem significado ao serem analisadas sozinhas. Sendo assim, muitos verbos, sauda√ß√µes, adv√©rbios e outros elementos s√£o adicionados 
nesta lista e n√£o se tornam n√≥s de um grafo.</p>

<p>A classe √© instanciada como abaixo:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">vec_alphanumeric</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">token_pattern</span><span class="o">=</span><span class="n">TOKENS_ALPHANUMERIC</span><span class="p">,</span> 
                                   <span class="n">decode_error</span><span class="o">=</span><span class="s">'replace'</span><span class="p">,</span>
                                   <span class="n">stop_words</span><span class="o">=</span><span class="n">STOP_WORDS</span><span class="p">,</span> <span class="n">ngram_range</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span>
                                   <span class="n">encoding</span><span class="o">=</span><span class="s">'latin1'</span><span class="p">,</span> <span class="n">strip_accents</span><span class="o">=</span><span class="s">'unicode'</span><span class="p">)</span>
</code></pre></div></div>

<p>e ao acessar <code class="language-plaintext highlighter-rouge">vec_alphanumeric.vocabulary_</code> temos acesso a um dicion√°rio no qual cada chave √© um conjunto de palavras e 
 o seu valor representa o n√∫mero de ocorr√™ncias no texto.</p>

<p>O grafo √© gerado usando a biblioteca <a href="https://networkx.github.io">NetworkX</a>. O m√©todo respons√°vel por sua cria√ß√£o recebe um par (chave, valor) do 
 dicion√°rio criado pelo CountVectorizer e da chave extrai todas as palavras, 
 criando um n√≥ para cada. Depois, forma pares dessas palavras e cria uma aresta para cada par com o peso sendo o valor recebido na entrada. 
 Se a aresta j√° existir, seu  peso √© somado √† frequ√™ncia da frase.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="k">def</span> <span class="nf">generate_graph</span><span class="p">(</span><span class="n">vocabulary</span><span class="p">):</span>

   <span class="c1"># Create a undirected graph
</span>   <span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="p">.</span><span class="n">Graph</span><span class="p">()</span>

   <span class="c1"># Iterate over each item of the vocabulary
</span>   <span class="k">for</span> <span class="n">phrase</span><span class="p">,</span> <span class="n">frequency</span> <span class="ow">in</span> <span class="n">vocabulary</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
     <span class="c1"># Get words in the phrase
</span>     <span class="n">words</span> <span class="o">=</span> <span class="n">phrase</span><span class="p">.</span><span class="n">split</span><span class="p">()</span>

     <span class="c1"># Using only tokens of length 2 or 5
</span>     <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">words</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">]:</span>
       <span class="k">continue</span>

     <span class="n">words_norm</span> <span class="o">=</span> <span class="p">[</span><span class="n">norm</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span> <span class="k">if</span> <span class="n">is_important</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="p">]</span>
     <span class="c1"># Extract unique words in the phrase
</span>     <span class="n">words_unique</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">words_norm</span><span class="p">))</span>

     <span class="c1"># Create a node if it does not exists already
</span>     <span class="n">G</span><span class="p">.</span><span class="n">add_nodes_from</span><span class="p">(</span><span class="n">words_unique</span><span class="p">)</span>

     <span class="c1"># Form combinations of 2 from the words
</span>     <span class="c1"># which will be a edge
</span>     <span class="n">pair</span> <span class="o">=</span> <span class="n">combinations</span><span class="p">(</span><span class="n">words_unique</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> 

     <span class="k">for</span> <span class="n">word1</span><span class="p">,</span> <span class="n">word2</span> <span class="ow">in</span> <span class="n">pair</span><span class="p">:</span>
       <span class="n">edge</span> <span class="o">=</span> <span class="p">(</span><span class="n">word1</span><span class="p">,</span> <span class="n">word2</span><span class="p">)</span>
       <span class="c1"># Increments weight of edge
</span>       <span class="c1"># if it already exists
</span>       <span class="c1"># Otherwise, create a new edge
</span>       <span class="k">if</span> <span class="n">edge</span> <span class="ow">in</span> <span class="n">G</span><span class="p">.</span><span class="n">edges</span><span class="p">:</span>
         <span class="n">G</span><span class="p">.</span><span class="n">edges</span><span class="p">[</span><span class="n">word1</span><span class="p">,</span> <span class="n">word2</span><span class="p">][</span><span class="s">'weight'</span><span class="p">]</span> <span class="o">+=</span> <span class="n">frequency</span>
       <span class="k">else</span><span class="p">:</span>
         <span class="n">G</span><span class="p">.</span><span class="n">add_weighted_edges_from</span><span class="p">([(</span><span class="n">word1</span><span class="p">,</span> <span class="n">word2</span><span class="p">,</span> <span class="n">frequency</span><span class="p">)])</span>

   <span class="k">return</span> <span class="n">G</span>
</code></pre></div></div>

<p>A fun√ß√£o <code class="language-plaintext highlighter-rouge">norm</code> √© usada para evitar repeti√ß√µes causadas por palavras no plural ou algumas conjuga√ß√µes de verbos.</p>

<p>Com isso, obtemos nossos lindos grafos que ser√£o analisados na pr√≥xima se√ß√£o.</p>

<h2 id="ligando-os-pontos">Ligando os pontos</h2>

<p>Neste estudo, s√£o usados todos os discursos de deputados de um mesmo partido. Os partidos gerados s√£o PSL, PT, PDT e NOVO.</p>

<p>Os conceitos utilizados para extrair informa√ß√µes s√£o os de cliques e centralidade. Uma clique nada mais √© do que um subconjunto 
de n√≥s que s√£o totalmente conectados entre si. √â um conceito geralmente usado para representar um grupo (de pessoas) no qual 
todas se conhecem, que aqui usamos para detectar um grupo de palavras que aparecem no mesmo contexto.</p>

<p>J√° a centralidade √© uma medida que ajuda a identificar n√≥s importantes no grafo. Usamos a centralidade de grau, que mede o n√∫mero de liga√ß√µes (arestas) que incidem em um n√≥. Como estamos lidando com um grafo n√£o direcionado, esse n√∫mero √© o mesmo n√∫mero de arestas que est√£o ligadas ao n√≥. Esse indicador √© usado para colorir cada n√≥ dos grafos abaixos, gerados com a biblioteca <a href="https://nxviz.readthedocs.io/en/latest/modules.html">nxviz</a>.</p>

<h3 id="psl">PSL</h3>

<p>A clique que obtemos com o grafo gerado com discursos de deputados do PSL comprova a intui√ß√£o que temos 
ao pensar nesse partido. Seguran√ßa e pol√≠cia, que s√£o temas que associamos √†s promessas dos 
candidatos, est√£o presentes.</p>

<p><img src="../images/posts/graph_psl.png" alt="PSL" /></p>

<p>Uma pauta recorrente no congresso e cuja apari√ß√£o era esperada √© a 
reforma da previd√™ncia, que pode justificar o n√≥ ‚Äúreforma‚Äù neste grafo.</p>

<h3 id="pt">PT</h3>

<p>J√° analisando o discurso do PT, na maior clique aparecem termos como educa√ß√£o, direito, social e sa√∫de
que s√£o diretamente ligados √†s principais pautas do partido.</p>

<p><img src="../images/posts/graph_pt.png" alt="PT" /></p>

<p>√â esperado tamb√©m a presen√ßa de ‚Äúdefesa‚Äù, visto que ‚Äúem defesa da educa√ß√£o‚Äù √© uma frase frequentemente 
usada para falar das greves e protestos contra os <del>cortes</del> contigenciamentos das verbas para 
a educa√ß√£o. Isso tamb√©m pode justificar a presen√ßa da palavra ‚Äúministro‚Äù, que foi muito criticado por falta de comunica√ß√£o e por suas decis√µes.</p>

<p>O tema de reforma da previd√™ncia tamb√©m aparece neste grafo, o que n√£o surpreende dada a posi√ß√£o 
forte do partido contra a mesma.</p>

<h3 id="novo">NOVO</h3>

<p>O grafo do NOVO difere dos demais, sem conter palavras comuns como ‚Äúestado‚Äù e ‚Äúgoverno‚Äù, 
mas apresenta ‚Äúreforma‚Äù e ‚Äúprevidencia‚Äù, como seria esperado do partido que defende 
a reforma.</p>

<p><img src="../images/posts/graph_novo.png" alt="NOVO" /></p>

<p>√â interessante ver que assuntos como renda e d√©ficit s√£o temas
que o deputados do NOVO mais gostam de citar e discutir.</p>

<h3 id="pdt">PDT</h3>

<p>A clique obtida a partir dos discursos do PDT  √© a que mais se diferencia, 
sem conter nenhuma das palavras comuns aos anteriores.</p>

<p><img src="../images/posts/graph_pdt.png" alt="PDT" /></p>

<p>√â curioso aparecerem nomes pr√≥prios como ‚Äúflavio‚Äù e ‚Äúgeovania‚Äù, al√©m dos termos como 
‚Äúdiscurso‚Äù, ‚Äúpedido‚Äù, ‚Äúcomunicacao‚Äù e ‚Äúregistro‚Äù.</p>

<h2 id="considera√ß√µes-finais">Considera√ß√µes finais</h2>

<p>Como qualquer estudante de ci√™ncia da computa√ß√£o nota em algum ponto de sua trajet√≥ria acad√™mica, os grafos possuem as mais variadas aplica√ß√µes. Neste caso, serviram para trazer palavras-chave dos discursos dos deputados entre janeiro e junho de 2019.</p>

<p>Com poucas m√©tricas, j√° foi poss√≠vel notar como os temas educa√ß√£o e reforma da previd√™ncia movimentaram a c√¢mara nesses primeiros 6 meses, levando-se em considera√ß√£o os 4 partidos analisados. Isso serve de est√≠mulo para usar grafos, al√©m de outras t√©cnicas, para promover o monitoramento das a√ß√µes dos pol√≠ticos, incentivando, assim, a participa√ß√£o da popula√ß√£o brasileira.</p>

<h2 id="links">Links</h2>

<p><a href="https://www.datacamp.com/courses/network-analysis-in-python-part-1">Curso do Datacamp sobre an√°lise de redes (ingl√™s)</a></p>

<p><a href="https://en.wikipedia.org/wiki/Clique_(graph_theory)">Verbete sobre cliques (ingl√™s)</a></p>

<p><a href="https://pt.wikipedia.org/wiki/Centralidade">Verbete sobre centralidade</a></p>

<p>At√© a pr√≥xima!</p>
:ET